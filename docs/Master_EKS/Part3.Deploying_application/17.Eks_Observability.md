# EKS Observability

## Overview

Observability is the ability to understand the internal state of a system from its external outputs. For EKS, this includes:

- **Logs**: Record of events and activities
- **Metrics**: Numerical measurements over time
- **Traces**: Request flow through distributed systems

Without observability, you cannot troubleshoot issues, understand capacity requirements, or optimize performance.

## Key Advantages of EKS Observability

### Pre-integrated with AWS Services
- CloudWatch integration out-of-the-box
- Control plane logs automatically available
- EC2 worker node metrics included
- Load balancer metrics integrated
- Other AWS service metrics (RDS, SQS, etc.)

### Comprehensive Coverage
- **Control Plane**: API server, scheduler, controller logs
- **Data Plane**: Node and Pod metrics
- **Applications**: Container logs and custom metrics
- **Network**: Load balancer and service mesh metrics

## Native AWS Tools

### CloudWatch Dashboard Creation

#### Basic EC2 Metrics Dashboard
```hcl
# Terraform example
data "aws_caller_identity" "current" {}

resource "aws_cloudwatch_dashboard" "simple_dashboard" {
  dashboard_name = "EKS-Dashboard"
  dashboard_body = jsonencode({
    widgets = [
      {
        type   = "explorer"
        width  = 24
        height = 2
        x      = 0
        y      = 0
        properties = {
          metrics = [
            {
              metricName   = "CPUUtilization"
              resourceType = "AWS::EC2::Instance"
              stat         = "Average"
            },
            {
              metricName   = "NetworkOut"
              resourceType = "AWS::EC2::Instance"
              stat         = "Average"
            }
          ]
          region = "eu-central-1"
          aggregateBy = {
            key  = "eks:nodegroup-name"
            func = "MAX"
          }
          labels = [
            {
              key   = "eks:cluster-name"
              value = "myipv4cluster"
            }
          ]
          widgetOptions = {
            legend = {
              position = "bottom"
            }
            view           = "timeSeries"
            rowsPerPage    = 1
            widgetsPerRow  = 2
          }
          period = 60
          title  = "Cluster EC2 Instances (aggregated)"
        }
      }
    ]
  })
}
```

### Control Plane Logs

#### Available Log Types
| Log Type | Description | Use Case |
|----------|-------------|----------|
| **Audit** | Records of API actions | Security, compliance, troubleshooting |
| **Authenticator** | IAM authentication records | Access control debugging |
| **API Server** | Component flags and configuration | Cluster configuration issues |
| **Controller** | Control loop actions | Scheduling and resource management |
| **Scheduler** | Pod placement decisions | Performance optimization |

#### Enable Control Plane Logging
```bash
# Enable audit and authenticator logs
aws eks update-cluster-config \
  --region eu-central-1 \
  --name myipv4cluster \
  --logging '{"clusterLogging":[{"types":["audit","authenticator"],"enabled":true}]}'

# Verify update status
aws eks describe-update \
  --region eu-central-1 \
  --name myipv4cluster \
  --update-id <update-id>
```

#### CloudWatch Log Insights Query Example
```sql
-- Query aws-auth ConfigMap access
fields @timestamp, @message
| filter @logStream like /audit/
| filter @message like /aws-auth/
| sort @timestamp desc
| limit 20
```

#### Cost Optimization - Log Retention
```bash
# Set retention policy (via AWS Console or CLI)
aws logs put-retention-policy \
  --log-group-name /aws/eks/myipv4cluster/cluster \
  --retention-in-days 30
```

**Retention Options:**
- 1 day to 10 years
- Typical: 30 days for cost optimization
- Consider compliance requirements

### Container Insights (CI)

#### Prerequisites
Add `CloudWatchAgentServerPolicy` to worker node IAM role.

#### Installation
```bash
# Set variables
ClusterName=myipv4cluster
RegionName=eu-central-1
FluentBitHttpPort='2020'
FluentBitReadFromHead='Off'
[[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off' || FluentBitReadFromTail='On'
[[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On'

# Deploy agents
curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | \
sed "s/{{cluster_name}}/${ClusterName}/;s/{{region_name}}/${RegionName}/;s/{{http_server_toggle}}/\"${FluentBitHttpServer}\"/;s/{{http_server_port}}/\"${FluentBitHttpPort}\"/;s/{{read_from_head}}/\"${FluentBitReadFromHead}\"/;s/{{read_from_tail}}/\"${FluentBitReadFromTail}\"/" | \
kubectl apply -f -

# Verify deployment
kubectl get pods -n amazon-cloudwatch
```

#### Log Groups Created by CI
| Log Group | Source | Content |
|-----------|--------|---------|
| `/aws/containerinsights/Cluster_Name/application` | `/var/log/containers` | Container stdout/stderr logs |
| `/aws/containerinsights/Cluster_Name/host` | `/var/log/dmesg`, `/var/log/secure`, `/var/log/messages` | System logs |
| `/aws/containerinsights/Cluster_Name/dataplane` | `/var/log/journal` | kubelet, kubeproxy, docker logs |
| `/aws/containerinsights/Cluster_Name/performance` | K8s API | Performance events and metrics |

#### Example Application for Testing
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: logger
  namespace: logger-app
spec:
  containers:
  - image: busybox
    command: ["/bin/sh"]
    args: ["-c", "for i in `seq 4`; do echo 'Logging Message'; done"]
    imagePullPolicy: IfNotPresent
    name: busybox
  restartPolicy: Never
```

#### CI Visualization Features
- **Map View**: Graphical cluster resource view with heat maps
- **Performance Dashboard**: CPU, memory, network metrics by namespace
- **Node View**: Individual instance metrics
- **Custom Metrics**: Application-specific measurements

**Cost Considerations:**
- Log storage charges apply
- Custom metrics pricing
- Review [CloudWatch pricing](https://aws.amazon.com/cloudwatch/pricing/)

## Managed Prometheus and Grafana

### Why Use Prometheus and Grafana?

#### Advantages
- **Open Source**: Wide community adoption
- **Reusable Dashboards**: Community-created visualizations
- **Multi-Source**: Not limited to AWS data sources
- **Rich Visualizations**: More complete than CloudWatch
- **Application Integration**: Easy custom metrics support
- **Flexibility**: Less vendor lock-in

#### Challenges (Solved by Managed Services)
- Infrastructure management overhead
- Long-term storage requirements
- High availability configuration
- Backup and recovery

### AWS Managed Prometheus (AMP) Setup

#### Create Workspace
```hcl
# Terraform
resource "aws_prometheus_workspace" "myamp" {
  alias = "myamp"
}
```

```bash
# Verify workspace
aws amp list-workspaces
aws amp describe-workspace --workspace-id <workspace-id>
```

### AWS Distro for OpenTelemetry (ADOT) Setup

#### Prerequisites
```bash
# Create namespace and service account
kubectl create ns prometheus

# Create IRSA for AMP access
eksctl create iamserviceaccount \
  --name amp-iamproxy-ingest-role \
  --namespace prometheus \
  --cluster myipv4cluster \
  --attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \
  --approve --override-existing-serviceaccounts

# Install cert-manager (required for ADOT)
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.8.2/cert-manager.yaml

# Verify cert-manager
kubectl get pods -n cert-manager
```

#### Install ADOT Add-on
```bash
# Apply permissions
kubectl apply -f https://amazon-eks.s3.amazonaws.com/docs/addons-otel-permissions.yaml

# Install ADOT add-on
CLUSTER_NAME=myipv4cluster
aws eks create-addon \
  --addon-name adot \
  --addon-version v0.51.0-eksbuild.1 \
  --cluster-name $CLUSTER_NAME

# Verify installation
aws eks describe-addon --addon-name adot --cluster-name $CLUSTER_NAME
```

#### Configure ADOT for Prometheus
```bash
# Set variables
AMP_REMOTE_WRITE_URL="https://aps-workspaces.eu-central-1.amazonaws.com/workspaces/<workspace-id>/api/v1/remote_write"
AWS_REGION=eu-central-1

# Download and modify configuration
curl -O https://raw.githubusercontent.com/aws-samples/one-observability-demo/main/PetAdoptions/cdk/pet_stack/resources/otel-collector-prometheus.yaml
sed -i -e "s/AWS_REGION/$AWS_REGION/g" otel-collector-prometheus.yaml
sed -i -e "s^AMP_WORKSPACE_URL^$AMP_REMOTE_WRITE_URL^g" otel-collector-prometheus.yaml

# Deploy ADOT collector
kubectl apply -f ./otel-collector-prometheus.yaml

# Verify deployment
kubectl get all -n prometheus
```

#### Test AMP Integration
```bash
# Install awscurl for API testing
pip3 install awscurl

# Query AMP
export AMP_QUERY_ENDPOINT="https://aps-workspaces.eu-central-1.amazonaws.com/workspaces/<workspace-id>/api/v1/query"
awscurl -X POST --region eu-central-1 --service aps "$AMP_QUERY_ENDPOINT?query=up" | jq .
```

### AWS Managed Grafana (AMG) Setup

#### Identity Center Setup
1. Enable AWS Identity Center through console
2. Create organization (if prompted)
3. Add user and verify email
4. Note user ID for workspace configuration

#### IAM Role for AMG
```hcl
# Terraform example
resource "aws_iam_role" "grafana_assume" {
  name = "grafana-assume"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "grafana.amazonaws.com"
        }
      }
    ]
  })
}

resource "aws_iam_policy" "amg_additional" {
  name        = "amg-additional"
  description = "Additional policies for AMG"
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "aps:ListWorkspaces",
          "aps:DescribeWorkspace",
          "aps:QueryMetrics",
          "aps:GetLabels",
          "aps:GetSeries",
          "aps:GetMetricMetadata"
        ]
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "amg_attachment" {
  role       = aws_iam_role.grafana_assume.name
  policy_arn = aws_iam_policy.amg_additional.arn
}
```

#### Create AMG Workspace
```hcl
resource "aws_grafana_workspace" "myamg" {
  account_access_type      = "CURRENT_ACCOUNT"
  authentication_providers = ["AWS_SSO"]
  permission_type          = "SERVICE_MANAGED"
  role_arn                 = aws_iam_role.grafana_assume.arn
  data_sources             = ["PROMETHEUS", "CLOUDWATCH"]
}

resource "aws_grafana_role_association" "admin" {
  role         = "ADMIN"
  user_ids     = ["<user-id-from-identity-center>"]
  workspace_id = aws_grafana_workspace.myamg.id
}
```

#### Configure Data Sources in Grafana
1. Access Grafana workspace URL
2. Login with Identity Center credentials
3. Click AWS icon → Data sources
4. Select "Amazon Managed Service for Prometheus"
5. Choose region and AMP workspace
6. Add data source

#### Import Community Dashboard
1. Click Create (+) → Import
2. Enter dashboard ID: **3119** (Kubernetes cluster monitoring)
3. Load and save dashboard
4. Select AMP data source

**Popular Kubernetes Dashboards:**
- **3119**: Kubernetes cluster monitoring
- **8588**: Kubernetes Deployment Statefulset Daemonset metrics
- **6417**: Kubernetes cluster monitoring (Prometheus)

## Distributed Tracing with OpenTelemetry

### Why Distributed Tracing?
In microservices architectures, a single request may span multiple services. Tracing helps:
- Track request flow across services
- Identify bottlenecks and latencies
- Debug complex distributed systems
- Monitor service dependencies

### OpenTelemetry (OTel) Overview
- **CNCF Project**: Vendor-agnostic observability framework
- **Instrumentation**: Libraries for automatic trace generation
- **Standards**: Consistent telemetry data format
- **Backends**: Supports multiple trace analysis tools

### Configure ADOT for Tracing

#### Add X-Ray Permissions
```bash
# Get IRSA role ARN
kubectl get sa amp-iamproxy-ingest-role -n prometheus -o jsonpath='{.metadata.annotations.eks\.amazonaws\.com/role-arn}'

# Add AWSXRayDaemonWriteAccess policy to the role via console or CLI
```

#### Update ADOT Configuration
Add to existing `otel-collector-prometheus.yaml`:
```yaml
spec:
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:
      batch/traces:
        timeout: 1s
        send_batch_size: 50
    
    exporters:
      awsxray:
        region: eu-central-1
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch/traces]
          exporters: [awsxray]
```

#### Deploy Sample Tracing Application
```bash
# Create namespace
kubectl create ns adot

# Download and modify sample app
curl -O https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/sample-app.yaml

# Modify environment variables:
# - AWS_REGION: your-region
# - OTEL_EXPORTER_OTLP_ENDPOINT: http://observability-collector.prometheus:4317
# - OTEL_RESOURCE_ATTRIBUTES: service.namespace=adot,service.name=emitter

kubectl apply -f sample-app-modified.yaml -n adot
```

#### Deploy Traffic Generator
```bash
# Download and deploy traffic generator
curl -O https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/traffic-generator.yaml
kubectl apply -f traffic-generator.yaml -n adot

# Verify deployment
kubectl get all -n adot
```

### X-Ray Analysis

#### Service Map
- Visual representation of service interactions
- Color coding for health status
- Size indicates traffic volume
- Latency overlays available

#### Trace Analysis
- End-to-end request tracking
- Segment timing information
- Error identification
- Performance bottleneck detection

**Key Metrics:**
- **Response Time**: Request duration
- **Throughput**: Requests per second
- **Error Rate**: Failed request percentage
- **Dependency Map**: Service relationships

## Machine Learning with DevOps Guru

### Overview
DevOps Guru uses pre-trained ML models to:
- Baseline resource usage patterns
- Detect anomalies automatically
- Provide insights without configuration
- Predict potential issues

### Setup Process
1. Navigate to Amazon DevOps Guru service
2. Click "Get Started"
3. Choose monitoring scope:
   - Current account
   - All resources or specific CloudFormation stacks
4. Enable service
5. Wait for initial analysis (20-90 minutes)

### Capabilities

#### Resource Analysis
- **High CPU/Memory utilization**
- **Filesystem usage patterns**
- **Pod resource limits**
- **Container restart patterns**
- **Image pull issues**
- **Application startup problems**

#### Insights Provided
- Resource exhaustion predictions
- Configuration recommendations
- Performance optimization suggestions
- Capacity planning guidance

#### Benefits
- **Zero operational overhead**
- **Continuous ML model improvements**
- **Automated anomaly detection**
- **Proactive issue identification**

**Cost Consideration:**
Review [DevOps Guru pricing](https://aws.amazon.com/devops-guru/pricing/) before implementation.

## Kubernetes Metrics API

### Native Metrics Access
```bash
# Get node metrics
kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes" | jq '.items[0]'

# Example output structure:
{
  "metadata": {
    "name": "ip-192-168-1-1.region.compute.internal",
    "creationTimestamp": "2023-03-18T15:23:51Z"
  },
  "timestamp": "2023-03-18T15:23:40Z",
  "window": "20.029s",
  "usage": {
    "cpu": "48636622n",    # Nanocores
    "memory": "1562400Ki"  # Kibibytes
  }
}

# Get pod metrics
kubectl get --raw "/apis/metrics.k8s.io/v1beta1/pods" | jq '.items[0]'
```

### Custom Metrics
For application-specific metrics:
```yaml
# Example custom metrics configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-metrics-config
data:
  metrics.yaml: |
    custom_metrics:
      - name: http_requests_total
        help: Total HTTP requests
        type: counter
        labels: [method, status]
      - name: request_duration_seconds
        help: Request duration
        type: histogram
        buckets: [0.1, 0.5, 1.0, 2.5, 5.0, 10.0]
```

## Best Practices

### Cost Optimization
1. **Log Retention**: Set appropriate retention periods
2. **Metric Resolution**: Use appropriate granularity
3. **Resource Targeting**: Monitor critical resources only
4. **Dashboard Efficiency**: Avoid excessive widgets
5. **Alert Optimization**: Prevent alert fatigue

### Security
1. **IAM Roles**: Use least privilege principle
2. **Data Encryption**: Enable in-transit and at-rest encryption
3. **Access Control**: Implement proper dashboard access
4. **Log Sanitization**: Remove sensitive information
5. **Audit Trails**: Monitor access to observability data

### Performance
1. **Sampling**: Use appropriate trace sampling rates
2. **Batching**: Configure efficient data batching
3. **Resource Limits**: Set appropriate agent resource limits
4. **Network Optimization**: Use VPC endpoints where possible
5. **Caching**: Implement dashboard caching strategies

### Operational Excellence
1. **Documentation**: Maintain runbooks and procedures
2. **Training**: Ensure team familiarity with tools
3. **Automation**: Automate common troubleshooting tasks
4. **Testing**: Regular observability stack testing
5. **Evolution**: Continuously improve monitoring coverage

## Tool Comparison

| Feature | CloudWatch | Prometheus + Grafana | Managed Services |
|---------|------------|---------------------|------------------|
| **Setup Complexity** | Low | High | Low |
| **Cost** | Pay per use | Infrastructure costs | Managed service pricing |
| **Flexibility** | AWS-focused | High | Medium-High |
| **Community** | AWS ecosystem | Large open source | Combined benefits |
| **Scalability** | Auto-scaling | Manual management | Auto-scaling |
| **Vendor Lock-in** | High | Low | Medium |
| **Advanced Features** | Good | Excellent | Excellent |
| **Learning Curve** | Low | Medium-High | Medium |

## Troubleshooting Guide

### Common Issues

#### ADOT Problems
```bash
# Check ADOT collector logs
kubectl logs observability-collector-<id> -n prometheus

# Common error patterns:
# - AWS credential issues
# - Network connectivity problems
# - Configuration syntax errors
# - Resource permission issues
```

#### Container Insights Issues
```bash
# Check agent status
kubectl get pods -n amazon-cloudwatch

# Check agent logs
kubectl logs <cloudwatch-agent-pod> -n amazon-cloudwatch
kubectl logs <fluent-bit-pod> -n amazon-cloudwatch

# Common issues:
# - IAM permission problems
# - Node resource constraints
# - Network policy blocking
```

#### Grafana Dashboard Problems
1. **No Data**: Verify data source configuration
2. **Authentication**: Check Identity Center setup
3. **Permissions**: Verify IAM role policies
4. **Queries**: Validate PromQL syntax

#### X-Ray Tracing Issues
1. **No Traces**: Check ADOT configuration and permissions
2. **Missing Segments**: Verify application instrumentation
3. **High Latency**: Check network connectivity
4. **Sampling**: Adjust sampling rates for visibility

## Key Takeaways

1. **Native Integration**: EKS provides extensive CloudWatch integration
2. **Choice of Tools**: Multiple observability options available
3. **Managed Services**: Reduce operational overhead with managed options
4. **Community Resources**: Leverage open source dashboards and tools
5. **Comprehensive Coverage**: Implement logs, metrics, and traces together
6. **Cost Awareness**: Monitor and optimize observability costs
7. **Automation**: Use Infrastructure as Code for observability setup
8. **Security**: Implement proper access controls and data protection

## Further Reading

- [EKS Observability Guide](https://docs.aws.amazon.com/eks/latest/userguide/eks-observe.html)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [OpenTelemetry Documentation](https://opentelemetry.io/docs/)
- [AWS X-Ray Developer Guide](https://docs.aws.amazon.com/xray/)
- [Container Insights Documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html)
- [DevOps Guru User Guide](https://docs.aws.amazon.com/devops-guru/)