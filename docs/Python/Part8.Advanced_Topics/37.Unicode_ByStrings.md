# Chapter 37: Unicode and Byte Strings

## Overview

Python 3.X elevates Unicode support from optional to essential, making it required reading for modern Python development. This chapter covers the full Unicode-text and binary-data string tales in Python.

## When You Need This Knowledge

### Required for:
- **Non-ASCII Unicode text**: Internet content, internationalized applications, XML parsers, GUIs
- **Binary data**: Image/audio files, network transfers, packed data with lower-level tools

### Optional for:
- Simple ASCII text applications (until you encounter different platforms/content)

## Unicode Foundations

### Character Representations

#### ASCII (American Standard Code for Information Interchange)
- Character codes 0-127 (7-bit range)
- Each character stored in one 8-bit byte
- Example: 'a' = 97 (0x61 in hex)

```python
>>> ord('a')       # Character => code
97
>>> chr(97)        # Code => character
'a'
>>> hex(97)        # Byte value: fits 8 bits
'0x61'
>>> 0b0111_1111    # Limit of ASCII's 7-bit range
127
```

#### Latin-1
- Uses all 8-bit byte values (0-255)
- Values 128-255 assigned to additional characters
- Example: 'Ã„' = 196 (0xc4)

```python
>>> chr(196)         # Too big for ASCII
'Ã„'
>>> ord('Ã„')         # Okay for Latin-1
196
>>> hex(ord('Ã„'))    # Byte value in Latin-1
'0xc4'
```

#### Unicode
- Defines character codes for almost every natural language
- Character codes called **code points** (integers)
- Examples:
  - 'a' = 97 (0x61)
  - 'Ã„' = 196 (0xc4)
  - 'ðŸ™‚' = 128578 (0x1f642)

```python
>>> [f'{c} is {ord(c)} and {hex(ord(c))}' for c in 'aÃ„ðŸ™‚']
['a is 97 and 0x61', 'Ã„ is 196 and 0xc4', 'ðŸ™‚ is 128578 and 0x1f642']
```

### Character Encodings

#### Key Concepts
- **Encoding**: Process of translating character string â†’ raw bytes
- **Decoding**: Process of translating raw bytes â†’ character string

#### Common Encodings

##### ASCII
- 1 byte per character (codes 0-127)
- Subset of Latin-1 and UTF-8

##### Latin-1
- 1 byte per character (codes 0-255)
- Backward compatible with ASCII

##### UTF-8 (Universal)
- Variable-length encoding (1-4 bytes per character)
- ASCII characters: 1 byte
- Codes 128-2047: 2 bytes
- Higher codes: 3-4 bytes
- De facto standard for text

```python
>>> len('a'.encode('UTF-8'))      # ASCII: 1 byte
1
>>> len('Ã„'.encode('UTF-8'))      # Non-ASCII: 2 bytes
2
>>> len('ðŸ™‚'.encode('UTF-8'))     # Emoji: 4 bytes
4
```

##### UTF-16 and UTF-32
- Fixed-length encodings (2 and 4 bytes per character)
- May include BOM (Byte Order Marker)

## Python String Types

### Three String Object Types

#### 1. `str` - Unicode Text
- For decoded Unicode text (code points)
- Immutable sequence of characters
- Default string type in Python 3.x

#### 2. `bytes` - Binary Data
- For raw binary content and encoded text
- Immutable sequence of 8-bit integers (0-255)
- Supports most string operations

#### 3. `bytearray` - Mutable Binary Data
- Mutable variant of `bytes`
- Supports in-place modifications

### String Literals

```python
>>> B = b'code'                # bytes literal
>>> S = 'hack'                 # str literal
>>> type(B), type(S)
(<class 'bytes'>, <class 'str'>)

>>> B[0], S[0]                 # Indexing: int vs str
(99, 'h')

>>> list(B), list(S)           # bytes is really integers
([99, 111, 100, 101], ['h', 'a', 'c', 'k'])
```

## String Type Conversions

### No Automatic Mixing
```python
>>> 'hack' + b'code'
TypeError: can only concatenate str (not "bytes") to str
```

### Manual Conversion Methods

#### str â†” bytes
```python
# str to bytes
>>> S = 'hack'
>>> S.encode()                     # Default UTF-8
b'hack'
>>> bytes(S, encoding='ascii')     # Alternative
b'hack'

# bytes to str
>>> B = b'code'
>>> B.decode()                     # Default UTF-8
'code'
>>> str(B, encoding='ascii')       # Alternative
'code'
```

### Mixing After Conversion
```python
>>> S, B = 'hack', b'code'
>>> S.encode('ascii') + B          # bytes + bytes
b'hackcode'
>>> S + B.decode('ascii')          # str + str
'hackcode'
```

## Coding Unicode Characters

### Escape Sequences

#### In `str` Objects (Code Points)
```python
>>> S = '\xc4\xe8'          # Hex escapes: code-point values
>>> S
'Ã„Ã¨'

>>> S = '\u00c4\u00e8'      # Unicode escapes: 16-bit
>>> S
'Ã„Ã¨'

>>> S = 'A\u00c4B\U000000e8C'  # 4 and 8 digit Unicode escapes
>>> S
'AÃ„BÃ¨C'
```

#### In `bytes` Objects (Byte Values)
```python
>>> B = b'A\xC4B\xE8C'           # Only hex escapes allowed
>>> B
b'A\xc4B\xe8C'

>>> B = b'A\u00C4B\U000000E8C'   # Unicode escapes taken literally!
SyntaxWarning: invalid escape sequence '\u'
>>> B
b'A\\u00C4B\\U000000E8C'
```

### Encoding Examples
```python
>>> S = '\u00c4\xe8'  # 'Ã„Ã¨'

# ASCII fails
>>> S.encode('ascii')
UnicodeEncodeError: 'ascii' codec can't encode characters...

# Latin-1: 1 byte per character
>>> S.encode('latin-1')
b'\xc4\xe8'

# UTF-8: 2 bytes per character  
>>> S.encode('utf-8')
b'\xc3\x84\xc3\xa8'
```

## Source File Encoding

### Default: UTF-8
Python uses UTF-8 by default for source code files.

### Custom Encoding Declaration
```python
# -*- coding: Latin-1 -*-
```

Must be first or second line in file. Allows embedding native Unicode characters in string literals.

### Example
```python
# -*- coding: Latin-1 -*-
myStr1 = 'AÃ„BÃ¨C'                    # Raw characters per source encoding
myStr2 = 'A\xc4B\xe8C'              # Hex escapes
myStr3 = 'A\u00c4B\U000000e8C'      # Unicode escapes
myStr4 = 'A' + chr(0xC4) + 'B' + chr(0xE8) + 'C'  # Concatenated
```

## Using Byte Strings

### Methods
`bytes` supports most `str` methods but returns `bytes` objects:

```python
>>> B = b'code'
>>> B.find(b'od')                  # Search
1
>>> B.replace(b'od', b'XY')        # Replace
b'cXYe'
```

### Sequence Operations
```python
>>> B = b'code'
>>> B[0], B[-1]           # Indexing returns integers
(99, 101)
>>> B[1:], B[:-1]         # Slicing returns bytes
(b'ode', b'cod')
>>> B + b'lmn'            # Concatenation
b'codelmn'
```

### Creating bytes Objects
```python
>>> bytes('abc', 'ascii')           # From string + encoding
b'abc'
>>> bytes([97, 98, 99])             # From integer list
b'abc'
>>> 'code'.encode()                 # From string encoding
b'code'
```

### Formatting
Only `%` formatting works with bytes (not `format()` or f-strings):

```python
>>> b'a %s string' % b'fine'        # Works
b'a fine string'

>>> b'a {} string'.format(b'fine')  # Doesn't work
AttributeError: 'bytes' object has no attribute 'format'
```

## The bytearray Object

### Mutable bytes
```python
>>> B = b'code'
>>> C = bytearray(B)
>>> C
bytearray(b'code')

# Modify in place (must use integers)
>>> C[0] = ord('x')
>>> C
bytearray(b'xode')

# List-like methods
>>> C.append(ord('!'))
>>> C.extend(b'ABC')
>>> C
bytearray(b'xode!ABC')
```

## Text and Binary Files

### File Modes Determine Types

#### Text Mode (default)
- Returns/expects `str` objects
- Automatic encoding/decoding
- Newline translation
- Universal newline support

#### Binary Mode (add 'b' to mode)
- Returns/expects `bytes`/`bytearray` objects
- No encoding/decoding
- No newline translation
- Raw data transfer

### Basic Examples

#### Text Files
```python
>>> open('temp.txt', 'w').write('abc\n')     # Text mode: str
4
>>> open('temp.txt', 'r').read()             # Returns str
'abc\n'
>>> open('temp.txt', 'rb').read()            # Binary mode: bytes
b'abc\r\n'  # Note: \r\n on Windows
```

#### Binary Files
```python
>>> open('temp.bin', 'wb').write(b'abc\n')   # Binary mode: bytes
4
>>> open('temp.bin', 'r').read()             # Text mode: str
'abc\n'
>>> open('temp.bin', 'rb').read()            # Binary mode: bytes
b'abc\n'
```

### Type Restrictions
```python
# These fail:
>>> open('temp.txt', 'w').write(b'abc\n')    # bytes to text file
TypeError: write() argument must be str, not bytes

>>> open('temp.bin', 'wb').write('abc\n')    # str to binary file
TypeError: a bytes-like object is required, not 'str'
```

## Unicode Text Files

### Explicit Encoding
Always specify encoding for non-ASCII text:

```python
# Writing Unicode
>>> file = open('uni.txt', 'w', encoding='utf8')
>>> file.write('ðŸ’› 2 hÃ„ck ðŸ')
10
>>> file.close()

# Reading Unicode
>>> text = open('uni.txt', 'r', encoding='utf8').read()
>>> text
'ðŸ’› 2 hÃ„ck ðŸ'

# Raw bytes view
>>> raw = open('uni.txt', 'rb').read()
>>> raw
b'\xf0\x9f\x92\x9b 2 h\xc3\x84ck \xf0\x9f\x90\x8d'
```

### Encoding Mismatches Fail
```python
>>> open('uni.txt', 'r', encoding='ascii').read()
UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0...
```

### Best Practices
1. **Always specify encoding** for text files when interoperability matters
2. **Use UTF-8** as default choice (universal support)
3. **Don't rely on platform defaults** (they vary)

## Platform Encoding Defaults

### Method Defaults
```python
>>> import sys, locale
>>> sys.getdefaultencoding()             # Methods default
'utf-8'
>>> locale.getpreferredencoding(False)   # open() default
'cp1252'  # Windows example
```

### Platform Differences
- **Windows**: Often cp1252 (Latin-1 superset)
- **Unix/macOS**: Usually UTF-8
- **Mobile**: Typically UTF-8

## String Tools and Unicode

### Regular Expressions (re module)
```python
>>> import re
>>> S = 'ðŸ is the fastest way to ðŸ•!'
>>> B = b'Python is the fastest way to pizza!'

>>> re.match('(.*) the (.*) way (.*)', S).groups()       # str
('ðŸ is', 'fastest', 'to ðŸ•!')
>>> re.match(b'(.*) the (.*) way (.*)', B).groups()      # bytes
(b'Python is', b'fastest', b'to pizza!')

# Cannot mix types
>>> re.match('(.*) the (.*) way (.*)', B)
TypeError: cannot use a string pattern on a bytes-like object
```

### Binary Data Processing (struct module)
```python
>>> import struct
>>> B = struct.pack('>i4sh', 7, b'code', 8)    # Pack to bytes
>>> B
b'\x00\x00\x00\x07code\x00\x08'
>>> struct.unpack('>i4sh', B)                   # Unpack from bytes
(7, b'code', 8)

# Use with binary files
>>> open('data.bin', 'wb').write(B)
>>> data = open('data.bin', 'rb').read()
>>> struct.unpack('>i4sh', data)
(7, b'code', 8)
```

### Serialization Modules

#### pickle (always produces bytes)
```python
>>> import pickle
>>> pickle.dumps(['code', 4, 'ðŸ'])           # Returns bytes
b'\x80\x04\x95...'

# Must use binary mode
>>> pickle.dump(['code', 4, 'ðŸ'], open('temp.pkl', 'wb'))
>>> pickle.load(open('temp.pkl', 'rb'))
['code', 4, 'ðŸ']
```

#### json (always produces str)
```python
>>> import json
>>> json.dumps(['code', {'app': ('ðŸ™‚', None, 1.23)}])
'["code", {"app": ["\\ud83d\\ude42", null, 1.23]}]'

# Use text mode
>>> json.dump(vals, open('data.txt', 'w', encoding='utf8'))
>>> json.load(open('data.txt', 'r', encoding='utf8'))
```

## Filenames and Unicode

### str Recommended for Filenames
```python
>>> name1 = 'hÃ„ckðŸ™‚1'                    # str filename
>>> open(name1, 'w', encoding='utf8').write('text1')

>>> name2_bytes = 'hÃ„ckðŸ™‚2'.encode('utf8')  # bytes filename
>>> open(name2_bytes, 'w', encoding='utf8').write('text2')

# Both work
>>> os.listdir('.')
['hÃ„ckðŸ™‚1', 'hÃ„ckðŸ™‚2']
```

### Directory Tools Support Both
```python
>>> os.listdir('.')                      # str â†’ str
['hÃ„ckðŸ™‚1', 'hÃ„ckðŸ™‚2']
>>> os.listdir(b'.')                     # bytes â†’ bytes
[b'h\xc3\x84ck\xf0\x9f\x99\x821', b'h\xc3\x84ck\xf0\x9f\x99\x822']

>>> glob.glob('h*')                      # Pattern matching
['hÃ„ckðŸ™‚1', 'hÃ„ckðŸ™‚2']
```

## Unicode Defaults and UTF-8 Mode

### Complex Default Story
- **Source code**: Always UTF-8
- **String methods**: Always UTF-8
- **Filenames**: Usually UTF-8 (via `sys.getfilesystemencoding()`)
- **File content**: Complex (platform-dependent)

### UTF-8 Mode (Python 3.7+)
Enable with:
- Environment: `PYTHONUTF8=1`
- Command line: `-X utf8`

Makes file operations use UTF-8 by default (recommended).

### Best Practice
**Always specify encodings explicitly** instead of relying on defaults:
```python
# Good
open('file.txt', 'r', encoding='utf-8')

# Risky (platform-dependent)
open('file.txt', 'r')
```

## Advanced Unicode Topics

### BOM (Byte Order Marker)

#### What is BOM?
Special byte sequence at start of files to specify:
- Data endianness (byte order)
- Encoding type declaration

#### UTF-8 BOM
```python
# utf-8: no BOM
>>> open('temp.txt', 'w', encoding='utf-8').write('code\nCODE\n')
>>> open('temp.txt', 'rb').read()
b'code\r\nCODE\r\n'

# utf-8-sig: adds/removes BOM
>>> open('temp.txt', 'w', encoding='utf-8-sig').write('code\nCODE\n')
>>> open('temp.txt', 'rb').read()
b'\xef\xbb\xbfcode\r\nCODE\r\n'  # BOM at start

>>> open('temp.txt', 'r', encoding='utf-8-sig').read()  # BOM stripped
'code\nCODE\n'
```

#### UTF-16 BOM
```python
>>> open('temp.txt', 'w', encoding='utf-16').write('code\nCODE\n')
>>> open('temp.txt', 'rb').read()
b'\xff\xfec\x00o\x00d\x00e\x00\r\x00\n\x00C\x00O\x00D\x00E\x00\r\x00\n\x00'
# BOM: \xff\xfe (little-endian)
```

### Unicode Normalization

#### The Problem
Same character, multiple representations:
```python
>>> L = '\u00F1'            # NFC form (composed)
>>> M = '\u006E\u0303'      # NFD form (decomposed)
>>> L, M                    # Same character
('Ã±', 'Ã±')
>>> L == M                  # But equality fails!
False
>>> len(L), len(M)          # Different code point counts
(1, 2)
```

#### The Solution
```python
>>> from unicodedata import normalize
>>> normalize('NFC', L) == normalize('NFC', M)    # Works!
True
>>> normalize('NFD', L) == normalize('NFD', M)    # Either form works
True
```

#### When to Normalize
- Cross-platform filename comparisons
- Text from arbitrary sources (internet content)
- Any Unicode equality testing

## Key Takeaways

### String Type Usage
- **`str`**: Decoded Unicode text (including ASCII)
- **`bytes`**: Binary data and encoded text
- **`bytearray`**: Mutable binary data

### File Mode Guidelines
- **Text mode**: For textual content (HTML, JSON, CSV, etc.)
- **Binary mode**: For binary content (images, audio, packed data)

### Best Practices
1. **Use explicit encodings** (don't rely on defaults)
2. **Choose UTF-8** when possible (universal support)
3. **Use `str` for filenames** (better portability)
4. **Normalize Unicode** for cross-platform text comparison
5. **Separate text and binary** processing clearly

### Common Patterns
```python
# Reading text with encoding
text = open('file.txt', 'r', encoding='utf-8').read()

# Reading binary data
data = open('file.bin', 'rb').read()

# Converting between types
text_bytes = text.encode('utf-8')
decoded_text = text_bytes.decode('utf-8')

# Normalizing for comparison
from unicodedata import normalize
if normalize('NFC', text1) == normalize('NFC', text2):
    print("Same text!")
```

This comprehensive understanding of Unicode and byte strings is essential for modern Python development, especially when dealing with internationalization, web content, or binary data processing.