# Python Comprehensions Interview Questions - Complete Guide

## ðŸ“š Table of Contents

### List Comprehensions (Questions 1-25)
### Dict Comprehensions (Questions 26-50)
### Set Comprehensions (Questions 51-75)
### Nested Comprehensions (Questions 76-100)

---

## ðŸ“ List Comprehensions

??? question "Q1: Basic list comprehension with conditions"

    ```python
    # Create list of squares for even numbers from 1 to 20
    squares = [x**2 for x in range(1, 21) if x % 2 == 0]
    print(squares)  # [4, 16, 36, 64, 100, 144, 196, 256, 324, 400]
    
    # Create list with conditional values
    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    result = [x if x % 2 == 0 else x * 2 for x in numbers]
    print(result)  # [2, 2, 6, 4, 10, 6, 14, 8, 18, 10]
    
    # Filter and transform strings
    words = ["apple", "banana", "cherry", "date"]
    uppercase_long = [word.upper() for word in words if len(word) > 4]
    print(uppercase_long)  # ['APPLE', 'BANANA', 'CHERRY']
    ```

??? question "Q2: List comprehension with lambda and built-in functions"

    ```python
    # Using lambda with filter and map
    numbers = range(1, 21)
    
    # Traditional approach
    even_squares = list(map(lambda x: x**2, filter(lambda x: x % 2 == 0, numbers)))
    print(even_squares)  # [4, 16, 36, 64, 100, 144, 196, 256, 324, 400]
    
    # List comprehension equivalent
    even_squares_comp = [x**2 for x in numbers if x % 2 == 0]
    
    # Using any() and all() in comprehensions
    nested_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    has_even = [any(x % 2 == 0 for x in sublist) for sublist in nested_lists]
    print(has_even)  # [True, True, True]
    
    all_positive = [all(x > 0 for x in sublist) for sublist in nested_lists]
    print(all_positive)  # [True, True, True]
    
    # Using enumerate and zip
    names = ["Alice", "Bob", "Charlie"]
    scores = [85, 92, 78]
    formatted = [f"{i+1}. {name}: {score}" for i, (name, score) in enumerate(zip(names, scores))]
    print(formatted)  # ['1. Alice: 85', '2. Bob: 92', '3. Charlie: 78']
    ```

??? question "Q3: List comprehension with string operations and built-ins"

    ```python
    # Extract vowels using filter and lambda
    text = "Hello World Python"
    vowels_filter = list(filter(lambda char: char.lower() in 'aeiou', text))
    vowels_comp = [char for char in text if char.lower() in 'aeiou']
    print(vowels_comp)  # ['e', 'o', 'o', 'y', 'o']
    
    # Using map with lambda for transformations
    words = ["hello", "world", "python"]
    reversed_map = list(map(lambda word: word[::-1], words))
    reversed_comp = [word[::-1] for word in words]
    print(reversed_comp)  # ['olleh', 'dlrow', 'nohtyp']
    
    # Complex string operations with zip
    sentence1 = "The quick brown fox"
    sentence2 = "Jumps over lazy dog"
    word_pairs = [f"{w1}-{w2}" for w1, w2 in zip(sentence1.split(), sentence2.split())]
    print(word_pairs)  # ['The-Jumps', 'quick-over', 'brown-lazy', 'fox-dog']
    
    # Using sorted with lambda
    words = ["apple", "pie", "cherry", "a"]
    sorted_by_length = sorted(words, key=lambda x: len(x))
    length_sorted_comp = [word for word in sorted(words, key=len)]
    print(length_sorted_comp)  # ['a', 'pie', 'apple', 'cherry']
    ```

??? question "Q4: Mathematical operations with lambda and built-ins"

    ```python
    # Prime numbers using lambda and all()
    is_prime = lambda n: n > 1 and all(n % i != 0 for i in range(2, int(n**0.5) + 1))
    primes = [n for n in range(2, 50) if is_prime(n)]
    print(primes[:10])  # [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
    
    # Using reduce with lambda (need to import)
    from functools import reduce
    numbers = [1, 2, 3, 4, 5]
    
    # Factorial using reduce
    factorial = lambda n: reduce(lambda x, y: x * y, range(1, n + 1), 1)
    factorials = [factorial(n) for n in range(1, 8)]
    print(factorials)  # [1, 2, 6, 24, 120, 720, 5040]
    
    # Using max, min, sum with lambda
    data = [(1, 10), (2, 5), (3, 8), (4, 12)]
    max_by_second = max(data, key=lambda x: x[1])
    maximums = [max(pair) for pair in data]
    print(maximums)  # [10, 5, 8, 12]
    
    # Statistical operations
    import statistics
    numbers_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    means = [statistics.mean(nums) for nums in numbers_list]
    print(means)  # [2.0, 5.0, 8.0]
    ```

??? question "Q5: Advanced filtering with any, all, and lambda"

    ```python
    # Complex filtering with any() and all()
    words = ["apple", "banana", "cherry", "date", "elderberry"]
    
    # Words with any vowel
    has_vowels = [word for word in words if any(char in 'aeiou' for char in word)]
    print(has_vowels)  # ['apple', 'banana', 'cherry', 'date', 'elderberry']
    
    # Words with all unique characters
    unique_chars = [word for word in words if len(word) == len(set(word))]
    print(unique_chars)  # ['cherry', 'date']
    
    # Using filter with multiple conditions
    students = [
        {"name": "Alice", "grades": [85, 90, 88]},
        {"name": "Bob", "grades": [78, 82, 75]},
        {"name": "Charlie", "grades": [92, 95, 89]}
    ]
    
    # Students with all grades above 80
    good_students = [s["name"] for s in students if all(grade >= 80 for grade in s["grades"])]
    print(good_students)  # ['Alice', 'Charlie']
    
    # Students with any grade above 90
    excellent_students = [s["name"] for s in students if any(grade > 90 for grade in s["grades"])]
    print(excellent_students)  # ['Alice', 'Charlie']
    ```

??? question "Q6: Flattening with zip and advanced operations"

    ```python
    # Flatten with zip and itertools
    from itertools import chain, zip_longest
    
    # Traditional flattening
    matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    flattened = list(chain.from_iterable(matrix))
    flattened_comp = [item for row in matrix for item in row]
    print(flattened_comp)  # [1, 2, 3, 4, 5, 6, 7, 8, 9]
    
    # Zip with different length lists
    list1 = [1, 2, 3]
    list2 = [4, 5, 6, 7, 8]
    list3 = [9, 10]
    
    # Using zip_longest with fillvalue
    zipped_longest = list(zip_longest(list1, list2, list3, fillvalue=0))
    sums_with_default = [sum(triple) for triple in zipped_longest]
    print(sums_with_default)  # [14, 17, 13, 7, 8]
    
    # Transpose using zip and unpacking
    matrix = [[1, 2, 3], [4, 5, 6]]
    transposed = list(zip(*matrix))
    transposed_comp = [[row[i] for row in matrix] for i in range(len(matrix[0]))]
    print(list(transposed))  # [(1, 4), (2, 5), (3, 6)]
    ```

??? question "Q7: String processing with built-in functions"

    ```python
    # Advanced string operations
    import re
    
    text = "The Quick Brown Fox Jumps Over The Lazy Dog"
    words = text.split()
    
    # Using sorted with multiple key functions
    sorted_words = sorted(words, key=lambda x: (len(x), x.lower()))
    custom_sorted = [word for word in sorted(words, key=lambda x: (len(x), x.lower()))]
    print(custom_sorted[:5])  # ['Dog', 'Fox', 'The', 'The', 'Over']
    
    # Using map with string methods
    capitalized = list(map(str.capitalize, [word.lower() for word in words]))
    capitalized_comp = [word.lower().capitalize() for word in words]
    print(capitalized_comp[:5])  # ['The', 'Quick', 'Brown', 'Fox', 'Jumps']
    
    # Pattern matching with filter
    emails = ["user@example.com", "invalid-email", "test@domain.org", "notanemail"]
    email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
    valid_emails = list(filter(email_pattern.match, emails))
    valid_emails_comp = [email for email in emails if email_pattern.match(email)]
    print(valid_emails_comp)  # ['user@example.com', 'test@domain.org']
    ```

??? question "Q8: Grouping and aggregation with lambda"

    ```python
    from itertools import groupby
    from collections import defaultdict
    
    # Group by first letter using groupby
    words = ["apple", "apricot", "banana", "blueberry", "cherry"]
    words.sort()  # groupby requires sorted data
    
    grouped_by_first = {k: list(g) for k, g in groupby(words, key=lambda x: x[0])}
    print(grouped_by_first)  # {'a': ['apple', 'apricot'], 'b': ['banana', 'blueberry'], 'c': ['cherry']}
    
    # Manual grouping with comprehension
    first_letters = {word[0] for word in words}
    manual_grouped = {letter: [word for word in words if word.startswith(letter)] 
                     for letter in first_letters}
    
    # Aggregate data
    sales_data = [
        ("Alice", "Jan", 1000),
        ("Bob", "Jan", 1200),
        ("Alice", "Feb", 1100),
        ("Bob", "Feb", 1300),
        ("Charlie", "Jan", 900)
    ]
    
    # Group by person and sum sales
    people = {person for person, _, _ in sales_data}
    sales_by_person = {person: sum(amount for p, _, amount in sales_data if p == person)
                      for person in people}
    print(sales_by_person)  # {'Alice': 2100, 'Bob': 2500, 'Charlie': 900}
    ```

---

## ðŸ—‚ï¸ Dictionary Comprehensions

??? question "Q26: Basic dictionary comprehensions with built-ins"

    ```python
    # Using zip to create dictionaries
    keys = ["name", "age", "city"]
    values = ["Alice", 25, "NYC"]
    person = dict(zip(keys, values))
    person_comp = {k: v for k, v in zip(keys, values)}
    print(person_comp)  # {'name': 'Alice', 'age': 25, 'city': 'NYC'}
    
    # Using enumerate for indexing
    fruits = ["apple", "banana", "cherry"]
    indexed = {i: fruit for i, fruit in enumerate(fruits)}
    print(indexed)  # {0: 'apple', 1: 'banana', 2: 'cherry'}
    
    # Character frequency with lambda
    text = "hello world"
    char_freq = {char: text.count(char) for char in set(text) if char != ' '}
    
    # Using filter and map
    numbers = range(1, 11)
    even_squares = dict(filter(lambda item: item[0] % 2 == 0, 
                              map(lambda x: (x, x**2), numbers)))
    even_squares_comp = {x: x**2 for x in numbers if x % 2 == 0}
    print(even_squares_comp)  # {2: 4, 4: 16, 6: 36, 8: 64, 10: 100}
    ```

??? question "Q27: Dictionary comprehension with lambda and conditions"

    ```python
    # Advanced filtering with lambda
    students = {"Alice": 85, "Bob": 78, "Charlie": 92, "Diana": 88}
    
    # Using filter with lambda
    high_scores_filter = dict(filter(lambda item: item[1] >= 85, students.items()))
    high_scores_comp = {name: score for name, score in students.items() if score >= 85}
    print(high_scores_comp)  # {'Alice': 85, 'Charlie': 92, 'Diana': 88}
    
    # Transform values with lambda
    transform_func = lambda score: 'A' if score >= 90 else 'B' if score >= 80 else 'C'
    grades = {name: transform_func(score) for name, score in students.items()}
    print(grades)  # {'Alice': 'B', 'Bob': 'C', 'Charlie': 'A', 'Diana': 'B'}
    
    # Complex conditions with any/all
    student_subjects = {
        "Alice": ["math", "science", "english"],
        "Bob": ["math", "history"],
        "Charlie": ["science", "english", "art"]
    }
    
    # Students taking any STEM subject
    stem_subjects = {"math", "science"}
    stem_students = {name: subjects for name, subjects in student_subjects.items()
                    if any(subject in stem_subjects for subject in subjects)}
    print(stem_students)  # {'Alice': ['math', 'science', 'english'], 'Bob': ['math', 'history'], 'Charlie': ['science', 'english', 'art']}
    ```

??? question "Q28: Dictionary operations with zip and map"

    ```python
    # Multiple lists to dictionary
    names = ["Alice", "Bob", "Charlie"]
    ages = [25, 30, 35]
    cities = ["NYC", "LA", "Chicago"]
    salaries = [50000, 60000, 70000]
    
    # Complex dictionary creation
    employees = {name: {"age": age, "city": city, "salary": salary}
                for name, age, city, salary in zip(names, ages, cities, salaries)}
    print(employees["Alice"])  # {'age': 25, 'city': 'NYC', 'salary': 50000}
    
    # Using map for transformations
    price_strings = ["$10.99", "$25.50", "$5.75"]
    clean_prices = list(map(lambda x: float(x.replace('$', '')), price_strings))
    price_dict = {f"item_{i}": price for i, price in enumerate(clean_prices)}
    print(price_dict)  # {'item_0': 10.99, 'item_1': 25.5, 'item_2': 5.75}
    
    # Statistical operations
    data_lists = {
        "scores_a": [85, 90, 78, 92],
        "scores_b": [88, 85, 95, 87],
        "scores_c": [90, 92, 89, 91]
    }
    
    # Apply multiple statistical functions
    import statistics
    stats = {name: {
        'mean': statistics.mean(values),
        'median': statistics.median(values),
        'max': max(values),
        'min': min(values)
    } for name, values in data_lists.items()}
    print(stats["scores_a"]["mean"])  # 86.25
    ```

??? question "Q29: Advanced grouping and aggregation"

    ```python
    from itertools import groupby
    from collections import defaultdict, Counter
    
    # Sales data processing
    transactions = [
        ("Alice", "Electronics", 1200),
        ("Bob", "Books", 50),
        ("Alice", "Books", 30),
        ("Charlie", "Electronics", 800),
        ("Bob", "Electronics", 400)
    ]
    
    # Group by person and sum by category
    people = {person for person, _, _ in transactions}
    sales_by_person_category = {
        person: {
            category: sum(amount for p, c, amount in transactions 
                         if p == person and c == category)
            for category in {cat for p, cat, _ in transactions if p == person}
        }
        for person in people
    }
    print(sales_by_person_category["Alice"])  # {'Electronics': 1200, 'Books': 30}
    
    # Using Counter for frequency analysis
    words = "the quick brown fox jumps over the lazy dog".split()
    word_freq = dict(Counter(words))
    
    # Custom frequency with conditions
    long_word_freq = {word: words.count(word) for word in set(words) if len(word) > 3}
    print(long_word_freq)  # {'quick': 1, 'brown': 1, 'jumps': 1, 'over': 1, 'lazy': 1}
    
    # Nested defaultdict simulation
    nested_data = [("A", "X", 10), ("A", "Y", 20), ("B", "X", 15)]
    nested_dict = {}
    for outer, inner, value in nested_data:
        if outer not in nested_dict:
            nested_dict[outer] = {}
        if inner not in nested_dict[outer]:
            nested_dict[outer][inner] = 0
        nested_dict[outer][inner] += value
    
    # Using comprehension
    outer_keys = {outer for outer, _, _ in nested_data}
    nested_comp = {
        outer: {
            inner: sum(value for o, i, value in nested_data if o == outer and i == inner)
            for inner in {inner for o, inner, _ in nested_data if o == outer}
        }
        for outer in outer_keys
    }
    print(nested_comp)  # {'A': {'X': 10, 'Y': 20}, 'B': {'X': 15}}
    ```

??? question "Q30: Dictionary comprehension with regex and advanced patterns"

    ```python
    import re
    from urllib.parse import urlparse
    
    # URL analysis
    urls = [
        "https://www.example.com/page1",
        "http://test.org/api/v1/users",
        "https://blog.site.net/post/123",
        "ftp://files.server.com/download"
    ]
    
    # Parse URLs with lambda
    parse_url = lambda url: urlparse(url)
    url_info = {url: {
        'scheme': parse_url(url).scheme,
        'domain': parse_url(url).netloc,
        'path': parse_url(url).path
    } for url in urls}
    
    # Extract domains
    domains = {url: urlparse(url).netloc for url in urls}
    print(domains)
    
    # Log analysis
    log_entries = [
        "2023-01-01 10:00:00 ERROR Failed to connect",
        "2023-01-01 10:01:00 INFO User logged in",
        "2023-01-01 10:02:00 WARNING Low disk space",
        "2023-01-01 10:03:00 ERROR Database timeout"
    ]
    
    # Extract log levels
    log_pattern = re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (\w+) (.+)')
    parsed_logs = {
        i: {
            'timestamp': match.group(1),
            'level': match.group(2),
            'message': match.group(3)
        }
        for i, entry in enumerate(log_entries)
        if (match := log_pattern.match(entry))
    }
    print(parsed_logs[0])  # {'timestamp': '2023-01-01 10:00:00', 'level': 'ERROR', 'message': 'Failed to connect'}
    ```

---

## ðŸ”¢ Set Comprehensions

??? question "Q51: Basic set comprehensions with built-ins"

    ```python
    # Set operations with lambda and filter
    numbers = range(1, 21)
    
    # Even squares using filter and map
    even_squares_filter = set(map(lambda x: x**2, filter(lambda x: x % 2 == 0, numbers)))
    even_squares_comp = {x**2 for x in numbers if x % 2 == 0}
    print(even_squares_comp)  # {64, 4, 36, 100, 16, 144, 196, 324, 256, 400}
    
    # Unique characters with filter
    text = "Hello World Programming"
    unique_letters = set(filter(str.isalpha, text.lower()))
    unique_letters_comp = {char for char in text.lower() if char.isalpha()}
    print(unique_letters_comp)  # {'l', 'w', 'r', 'p', 'g', 'd', 'h', 'a', 'n', 'o', 'e', 'm', 'i'}
    
    # Using any() for complex conditions
    words = ["python", "java", "javascript", "go", "rust"]
    words_with_vowels = {word for word in words if any(vowel in word for vowel in 'aeiou')}
    print(words_with_vowels)  # {'java', 'javascript'}
    ```

??? question "Q52: Set comprehensions with string processing"

    ```python
    import string
    
    # Advanced string analysis
    text = "The Quick Brown Fox Jumps Over The Lazy Dog"
    
    # Unique word lengths using map
    word_lengths = set(map(len, text.split()))
    word_lengths_comp = {len(word) for word in text.split()}
    print(word_lengths_comp)  # {3, 4, 5}
    
    # Consonants using set operations
    all_letters = set(string.ascii_lowercase)
    vowels = set('aeiou')
    consonants_in_text = {char.lower() for char in text if char.lower() in all_letters - vowels}
    print(len(consonants_in_text))  # Number of unique consonants
    
    # Words by category using lambda
    categorize_word = lambda word: 'short' if len(word) <= 3 else 'medium' if len(word) <= 6 else 'long'
    word_categories = {categorize_word(word) for word in text.split()}
    print(word_categories)  # {'short', 'medium'}
    
    # Palindrome detection
    test_words = ["radar", "hello", "level", "world", "madam", "noon", "python"]
    palindromes = {word for word in test_words if word == word[::-1]}
    print(palindromes)  # {'noon', 'radar', 'level', 'madam'}
    ```

??? question "Q53: Mathematical set operations with built-ins"

    ```python
    from math import sqrt, gcd
    from functools import reduce
    
    # Advanced mathematical sets
    numbers = range(1, 101)
    
    # Perfect squares using lambda
    perfect_squares = {n for n in numbers if int(sqrt(n))**2 == n}
    perfect_squares_lambda = set(filter(lambda n: int(sqrt(n))**2 == n, numbers))
    print(len(perfect_squares))  # 10
    
    # Prime numbers with optimized check
    def is_prime(n):
        return n > 1 and all(n % i != 0 for i in range(2, int(sqrt(n)) + 1))
    
    primes = {n for n in range(2, 100) if is_prime(n)}
    
    # Numbers with specific digit properties
    has_digit_sum_multiple_of_3 = {n for n in numbers if sum(int(digit) for digit in str(n)) % 3 == 0}
    
    # GCD operations
    number_pairs = [(12, 18), (15, 25), (7, 11), (24, 36)]
    gcds = {gcd(a, b) for a, b in number_pairs}
    print(gcds)  # {1, 5, 6, 12}
    
    # Fibonacci numbers up to limit
    def fibonacci_up_to(limit):
        fibs = {0, 1}
        a, b = 0, 1
        while b < limit:
            a, b = b, a + b
            fibs.add(b)
        return fibs
    
    fib_set = fibonacci_up_to(100)
    print(sorted(fib_set))
    ```

??? question "Q54: Set comprehensions with multiple data sources"

    ```python
    # Working with multiple datasets
    employees = [
        {"name": "Alice", "dept": "Engineering", "skills": ["Python", "Java"]},
        {"name": "Bob", "dept": "Marketing", "skills": ["Excel", "PowerPoint"]},
        {"name": "Charlie", "dept": "Engineering", "skills": ["Python", "JavaScript"]},
        {"name": "Diana", "dept": "Sales", "skills": ["CRM", "Excel"]}
    ]
    
    # Unique skills across all employees
    all_skills = {skill for emp in employees for skill in emp["skills"]}
    print(all_skills)  # {'Python', 'Java', 'Excel', 'PowerPoint', 'JavaScript', 'CRM'}
    
    # Departments with Python developers
    python_depts = {emp["dept"] for emp in employees if "Python" in emp["skills"]}
    print(python_depts)  # {'Engineering'}
    
    # Cross-department skill analysis
    engineering_skills = {skill for emp in employees if emp["dept"] == "Engineering" for skill in emp["skills"]}
    other_skills = {skill for emp in employees if emp["dept"] != "Engineering" for skill in emp["skills"]}
    
    # Skills unique to engineering
    unique_to_engineering = engineering_skills - other_skills
    print(unique_to_engineering)  # {'JavaScript', 'Java', 'Python'}
    
    # Skills shared across departments
    shared_skills = engineering_skills & other_skills
    print(shared_skills)  # set() (no shared skills in this example)
    ```

??? question "Q55: Advanced set operations with itertools"

    ```python
    from itertools import combinations, product, permutations
    
    # Combination analysis
    numbers = {1, 2, 3, 4, 5}
    
    # All pairs (combinations)
    pairs = {tuple(sorted(pair)) for pair in combinations(numbers, 2)}
    print(len(pairs))  # 10
    
    # Sums of all pairs
    pair_sums = {sum(pair) for pair in combinations(numbers, 2)}
    print(pair_sums)  # {3, 4, 5, 6, 7, 8, 9}
    
    # Products of pairs
    pair_products = {a * b for a, b in combinations(numbers, 2)}
    print(sorted(pair_products))
    
    # Advanced filtering with combinations
    valid_combinations = {combo for combo in combinations(range(1, 10), 3) 
                         if sum(combo) == 15 and all(x % 2 == 1 for x in combo)}
    print(valid_combinations)
    
    # Set operations with Cartesian product
    set1 = {1, 2, 3}
    set2 = {'a', 'b'}
    cartesian = {(x, y) for x in set1 for y in set2}
    # Equivalent to: set(product(set1, set2))
    print(cartesian)  # {(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b'), (3, 'a'), (3, 'b')}
    ```

---

## ðŸ”„ Nested Comprehensions

??? question "Q76: Matrix operations with lambda and built-ins"

    ```python
    import numpy as np  # Note: Use only if available
    from itertools import chain
    
    # Create and manipulate matrices
    rows, cols = 4, 5
    matrix = [[i * cols + j + 1 for j in range(cols)] for i in range(rows)]
    
    # Matrix operations with lambda
    transpose = list(map(list, zip(*matrix)))
    transpose_comp = [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]
    
    # Apply function to each element
    squared_matrix = [[x**2 for x in row] for row in matrix]
    squared_lambda = list(map(lambda row: list(map(lambda x: x**2, row)), matrix))
    
    # Conditional transformations
    processed_matrix = [[x if x % 2 == 0 else x * -1 for x in row] for row in matrix]
    
    # Matrix statistics
    row_sums = [sum(row) for row in matrix]
    col_sums = [sum(matrix[i][j] for i in range(len(matrix))) for j in range(len(matrix[0]))]
    
    # Find elements meeting criteria
    positions_of_evens = [(i, j) for i, row in enumerate(matrix) 
                          for j, val in enumerate(row) if val % 2 == 0]
    print(f"Even positions: {positions_of_evens[:5]}")
    
    # Flatten with conditions using chain
    flattened_evens = list(chain.from_iterable([[val for val in row if val % 2 == 0] for row in matrix]))
    flattened_comp = [val for row in matrix for val in row if val % 2 == 0]
    print(f"Even values: {flattened_comp[:10]}")
    ```

??? question "Q77: Advanced nested dictionary comprehensions"

    ```python
    from collections import defaultdict
    import json
    
    # Complex data structure creation
    students = [
        {"name": "Alice", "grade": "A", "subject": "Math", "score": 95},
        {"name": "Alice", "grade": "A", "subject": "Science", "score": 88},
        {"name": "Bob", "grade": "B", "subject": "Math", "score": 82},
        {"name": "Bob", "grade": "B", "subject": "Science", "score": 79},
        {"name": "Charlie", "grade": "A", "subject": "Math", "score": 91}
    ]
    
    # Multi-level grouping with statistics
    subjects = {s["subject"] for s in students}
    names = {s["name"] for s in students}
    
    # Nested dictionary with calculations
    student_analytics = {
        name: {
            subject: {
                'scores': [s["score"] for s in students if s["name"] == name and s["subject"] == subject],
                'average': sum(s["score"] for s in students if s["name"] == name and s["subject"] == subject) / 
                          len([s for s in students if s["name"] == name and s["subject"] == subject])
                          if [s for s in students if s["name"] == name and s["subject"] == subject] else 0,
                'grade': next((s["grade"] for s in students if s["name"] == name), "N/A")
            }
            for subject in {s["subject"] for s in students if s["name"] == name}
        }
        for name in names
    }
    
    # Using lambda for complex transformations
    grade_transformer = lambda score: 'A+' if score >= 95 else 'A' if score >= 90 else 'B+' if score >= 85 else 'B'
    
    performance_matrix = {
        name: {
            subject: {
                'numeric_score': scores[0] if scores else 0,
                'letter_grade': grade_transformer(scores[0]) if scores else 'F',
                'rank': 'Top' if scores and scores[0] >= 90 else 'Good' if scores and scores[0] >= 80 else 'Needs Improvement'
            }
            for subject in subjects
            for scores in [[s["score"] for s in students if s["name"] == name and s["subject"] == subject]]
            if scores
        }
        for name in names
    }
    
    print(f"Alice Math Performance: {performance_matrix['Alice']['Math']}")
    ```

??? question "Q78: Complex nested filtering with multiple conditions"

    ```python
    from datetime import datetime, timedelta
    import re
    
    # Complex dataset
    sales_data = [
        {"id": 1, "date": "2023-01-15", "customer": "Alice", "product": "Laptop", "amount": 1200, "region": "North"},
        {"id": 2, "date": "2023-01-16", "customer": "Bob", "product": "Mouse", "amount": 25, "region": "South"},
        {"id": 3, "date": "2023-02-01", "customer": "Alice", "product": "Keyboard", "amount": 75, "region": "North"},
        {"id": 4, "date": "2023-02-15", "customer": "Charlie", "product": "Monitor", "amount": 300, "region": "East"},
        {"id": 5, "date": "2023-03-01", "customer": "Diana", "product": "Laptop", "amount": 1100, "region": "West"}
    ]
    
    # Parse dates with lambda
    parse_date = lambda date_str: datetime.strptime(date_str, "%Y-%m-%d")
    
    # Multi-dimensional analysis
    regions = {sale["region"] for sale in sales_data}
    months = {parse_date(sale["date"]).strftime("%Y-%m") for sale in sales_data}
    
    # Complex nested structure with conditions
    regional_monthly_analysis = {
        region: {
            month: {
                'total_sales': sum(sale["amount"] for sale in sales_data 
                                 if sale["region"] == region and 
                                 parse_date(sale["date"]).strftime("%Y-%m") == month),
                'transaction_count': len([sale for sale in sales_data 
                                        if sale["region"] == region and 
                                        parse_date(sale["date"]).strftime("%Y-%m") == month]),
                'customers': {sale["customer"] for sale in sales_data 
                            if sale["region"] == region and 
                            parse_date(sale["date"]).strftime("%Y-%m") == month},
                'products': [sale["product"] for sale in sales_data 
                           if sale["region"] == region and 
                           parse_date(sale["date"]).strftime("%Y-%m") == month],
                'high_value_transactions': [sale for sale in sales_data 
                                          if sale["region"] == region and 
                                          parse_date(sale["date"]).strftime("%Y-%m") == month and 
                                          sale["amount"] > 100]
            }
            for month in months
            if any(sale["region"] == region and parse_date(sale["date"]).strftime("%Y-%m") == month 
                  for sale in sales_data)
        }
        for region in regions
    }
    
    # Customer segmentation with nested conditions
    customer_segments = {
        customer: {
            'total_spent': sum(sale["amount"] for sale in sales_data if sale["customer"] == customer),
            'regions_active': {sale["region"] for sale in sales_data if sale["customer"] == customer},
            'product_diversity': len({sale["product"] for sale in sales_data if sale["customer"] == customer}),
            'segment': 'Premium' if sum(sale["amount"] for sale in sales_data if sale["customer"] == customer) > 500
                      else 'Regular' if sum(sale["amount"] for sale in sales_data if sale["customer"] == customer) > 100
                      else 'Basic',
            'purchase_pattern': {
                'avg_purchase': sum(sale["amount"] for sale in sales_data if sale["customer"] == customer) / 
                               len([sale for sale in sales_data if sale["customer"] == customer]),
                'frequency': len([sale for sale in sales_data if sale["customer"] == customer])
            }
        }
        for customer in {sale["customer"] for sale in sales_data}
    }
    
    print(f"Alice's segment: {customer_segments['Alice']['segment']}")
    ```

??? question "Q79: Nested comprehensions with advanced string processing"

    ```python
    import re
    from collections import Counter
    
    # Complex text data
    documents = [
        {
            "title": "Python Programming Guide",
            "content": "Python is a powerful programming language. It supports object-oriented programming.",
            "tags": ["python", "programming", "tutorial"],
            "author": "Alice",
            "word_count": 12
        },
        {
            "title": "Data Science with Python",
            "content": "Data science involves statistics, machine learning, and programming skills.",
            "tags": ["data-science", "python", "machine-learning"],
            "author": "Bob",
            "word_count": 10
        },
        {
            "title": "Web Development Basics",
            "content": "Web development requires HTML, CSS, and JavaScript knowledge.",
            "tags": ["web-development", "html", "css", "javascript"],
            "author": "Charlie",
            "word_count": 9
        }
    ]
    
    # Advanced text analysis with nested comprehensions
    stop_words = {"a", "an", "and", "the", "is", "it", "in", "on", "at", "to", "for", "of", "with", "by"}
    
    # Document analysis matrix
    doc_analysis = {
        doc["title"]: {
            'content_words': [word.lower() for word in re.findall(r'\b\w+\b', doc["content"]) 
                            if word.lower() not in stop_words and len(word) > 2],
            'unique_words': {word.lower() for word in re.findall(r'\b\w+\b', doc["content"]) 
                           if word.lower() not in stop_words and len(word) > 2},
            'word_frequency': dict(Counter(word.lower() for word in re.findall(r'\b\w+\b', doc["content"]) 
                                         if word.lower() not in stop_words)),
            'readability_score': len([word for word in re.findall(r'\b\w+\b', doc["content"]) if len(word) > 6]) / 
                               len(re.findall(r'\b\w+\b', doc["content"])) * 100,
            'tag_categories': {
                'technical': [tag for tag in doc["tags"] if any(tech_term in tag for tech_term in ['python', 'programming', 'development'])],
                'domain': [tag for tag in doc["tags"] if any(domain_term in tag for domain_term in ['science', 'web', 'data'])],
                'general': [tag for tag in doc["tags"] if not any(term in tag for term in ['python', 'programming', 'development', 'science', 'web', 'data'])]
            }
        }
        for doc in documents
    }
    
    # Cross-document analysis
    all_words = {word for doc in documents for word in re.findall(r'\b\w+\b', doc["content"].lower()) 
                if word not in stop_words and len(word) > 2}
    
    # Word co-occurrence matrix
    word_cooccurrence = {
        word1: {
            word2: sum(1 for doc in documents 
                      if word1 in doc["content"].lower() and word2 in doc["content"].lower())
            for word2 in all_words if word2 != word1
        }
        for word1 in all_words
    }
    
    # Author analysis
    authors = {doc["author"] for doc in documents}
    author_profiles = {
        author: {
            'document_count': len([doc for doc in documents if doc["author"] == author]),
            'total_words': sum(doc["word_count"] for doc in documents if doc["author"] == author),
            'topics': {tag for doc in documents if doc["author"] == author for tag in doc["tags"]},
            'vocabulary_richness': len({word.lower() for doc in documents if doc["author"] == author 
                                      for word in re.findall(r'\b\w+\b', doc["content"]) 
                                      if word.lower() not in stop_words}),
            'specialization': Counter(tag for doc in documents if doc["author"] == author for tag in doc["tags"]).most_common(3)
        }
        for author in authors
    }
    
    print(f"Alice's specialization: {author_profiles['Alice']['specialization']}")
    ```

??? question "Q80: Performance optimization with nested comprehensions"

    ```python
    import time
    from functools import reduce
    from itertools import product, combinations
    
    # Performance comparison examples
    def time_comprehension(func, name):
        start = time.time()
        result = func()
        end = time.time()
        print(f"{name}: {end - start:.4f} seconds")
        return result
    
    # Large dataset for performance testing
    large_matrix = [[i * 100 + j for j in range(100)] for i in range(100)]
    
    # Method 1: Nested loops (traditional)
    def traditional_approach():
        result = []
        for i, row in enumerate(large_matrix):
            for j, val in enumerate(row):
                if val % 7 == 0 and val > 1000:
                    result.append((i, j, val))
        return result
    
    # Method 2: Nested comprehension
    def comprehension_approach():
        return [(i, j, val) for i, row in enumerate(large_matrix) 
                for j, val in enumerate(row) if val % 7 == 0 and val > 1000]
    
    # Method 3: Filter and map combination
    def functional_approach():
        flattened = [(i, j, val) for i, row in enumerate(large_matrix) 
                    for j, val in enumerate(row)]
        return list(filter(lambda x: x[2] % 7 == 0 and x[2] > 1000, flattened))
    
    # Performance testing
    result1 = time_comprehension(traditional_approach, "Traditional loops")
    result2 = time_comprehension(comprehension_approach, "List comprehension")
    result3 = time_comprehension(functional_approach, "Functional approach")
    
    # Memory-efficient generators
    def generator_approach():
        return ((i, j, val) for i, row in enumerate(large_matrix) 
                for j, val in enumerate(row) if val % 7 == 0 and val > 1000)
    
    # Complex nested operations optimization
    data_cube = [[[x * y * z for z in range(10)] for y in range(10)] for x in range(10)]
    
    # Optimized aggregation
    layer_sums = [sum(sum(row) for row in layer) for layer in data_cube]
    
    # Multi-dimensional slicing
    diagonal_3d = [data_cube[i][i][i] for i in range(min(len(data_cube), len(data_cube[0]), len(data_cube[0][0])))]
    
    # Advanced pattern matching
    pattern_matches = [
        (x, y, z) for x in range(len(data_cube))
        for y in range(len(data_cube[x]))
        for z in range(len(data_cube[x][y]))
        if data_cube[x][y][z] > 100 and (x + y + z) % 3 == 0
    ]
    
    print(f"Found {len(pattern_matches)} pattern matches")
    ```

??? question "Q81-100: Advanced Integration Challenges"

    ```python
    # Challenge problems combining all concepts
    
    # Q81: Advanced data pipeline with comprehensions
    import json
    from datetime import datetime
    import statistics
    
    # Complex dataset simulation
    raw_data = [
        {"timestamp": "2023-01-01T10:00:00", "user_id": 1, "action": "login", "device": "mobile", "location": "US"},
        {"timestamp": "2023-01-01T10:05:00", "user_id": 1, "action": "purchase", "device": "mobile", "amount": 99.99},
        {"timestamp": "2023-01-01T11:00:00", "user_id": 2, "action": "login", "device": "desktop", "location": "UK"},
        {"timestamp": "2023-01-01T11:30:00", "user_id": 2, "action": "view", "device": "desktop", "product_id": "P123"},
    ]
    
    # Advanced data transformation pipeline
    processed_data = {
        user_id: {
            'session_count': len({datetime.fromisoformat(event["timestamp"]).date() 
                                for event in raw_data if event["user_id"] == user_id}),
            'total_purchases': sum(event.get("amount", 0) for event in raw_data 
                                 if event["user_id"] == user_id and event["action"] == "purchase"),
            'device_usage': dict(Counter(event["device"] for event in raw_data if event["user_id"] == user_id)),
            'activity_timeline': sorted([
                {
                    'time': datetime.fromisoformat(event["timestamp"]),
                    'action': event["action"],
                    'details': {k: v for k, v in event.items() if k not in ['timestamp', 'user_id', 'action']}
                }
                for event in raw_data if event["user_id"] == user_id
            ], key=lambda x: x['time'])
        }
        for user_id in {event["user_id"] for event in raw_data}
    }
    
    # Q82: Machine Learning Feature Engineering
    # Simulated ML dataset
    ml_data = [
        {"features": [1.2, 2.3, 3.4, 4.5], "label": 1, "category": "A"},
        {"features": [2.1, 3.2, 4.3, 5.4], "label": 0, "category": "B"},
        {"features": [1.5, 2.6, 3.7, 4.8], "label": 1, "category": "A"},
    ]
    
    # Feature engineering with comprehensions
    feature_stats = {
        f"feature_{i}": {
            'mean': statistics.mean(row["features"][i] for row in ml_data),
            'std': statistics.stdev(row["features"][i] for row in ml_data) if len(ml_data) > 1 else 0,
            'min': min(row["features"][i] for row in ml_data),
            'max': max(row["features"][i] for row in ml_data)
        }
        for i in range(len(ml_data[0]["features"]))
    }
    
    # Normalized features
    normalized_data = [
        {
            **row,
            'normalized_features': [
                (row["features"][i] - feature_stats[f"feature_{i}"]['mean']) / 
                (feature_stats[f"feature_{i}"]['std'] if feature_stats[f"feature_{i}"]['std'] > 0 else 1)
                for i in range(len(row["features"]))
            ]
        }
        for row in ml_data
    ]
    
    # Q83: Advanced Graph Operations
    # Graph represented as adjacency list
    graph = {
        'A': ['B', 'C'],
        'B': ['A', 'D', 'E'],
        'C': ['A', 'F'],
        'D': ['B'],
        'E': ['B', 'F'],
        'F': ['C', 'E']
    }
    
    # Graph analysis with comprehensions
    graph_metrics = {
        node: {
            'degree': len(neighbors),
            'neighbors': set(neighbors),
            'two_hop_neighbors': {n2 for n1 in neighbors for n2 in graph.get(n1, []) if n2 != node},
            'clustering_coefficient': len({(n1, n2) for n1 in neighbors for n2 in neighbors 
                                         if n1 != n2 and n2 in graph.get(n1, [])}) / 
                                    (len(neighbors) * (len(neighbors) - 1)) if len(neighbors) > 1 else 0
        }
        for node, neighbors in graph.items()
    }
    
    # Q84: Advanced Text Analysis Pipeline
    text_corpus = [
        "Machine learning algorithms can learn patterns from data automatically.",
        "Deep learning is a subset of machine learning using neural networks.",
        "Natural language processing helps computers understand human language.",
        "Computer vision enables machines to interpret visual information."
    ]
    
    # Advanced NLP pipeline with comprehensions
    import re
    from collections import defaultdict
    
    # Preprocessing pipeline
    processed_corpus = {
        i: {
            'original': text,
            'tokens': re.findall(r'\b\w+\b', text.lower()),
            'filtered_tokens': [word for word in re.findall(r'\b\w+\b', text.lower()) 
                              if len(word) > 2 and word not in stop_words],
            'pos_tags': [(word, 'NOUN' if word.endswith('ing') else 'VERB' if word.endswith('s') else 'ADJ') 
                        for word in re.findall(r'\b\w+\b', text.lower())],  # Simplified POS tagging
            'ngrams': [' '.join(tokens[i:i+2]) for tokens in [re.findall(r'\b\w+\b', text.lower())] 
                      for i in range(len(tokens)-1)],
            'sentence_metrics': {
                'length': len(text),
                'word_count': len(re.findall(r'\b\w+\b', text)),
                'complexity': len([word for word in re.findall(r'\b\w+\b', text) if len(word) > 6]) / 
                            len(re.findall(r'\b\w+\b', text))
            }
        }
        for i, text in enumerate(text_corpus)
    }
    
    # Document similarity matrix
    all_tokens = {token for doc in processed_corpus.values() for token in doc['filtered_tokens']}
    
    similarity_matrix = {
        (i, j): len(set(processed_corpus[i]['filtered_tokens']) & 
                   set(processed_corpus[j]['filtered_tokens'])) / 
               len(set(processed_corpus[i]['filtered_tokens']) | 
                   set(processed_corpus[j]['filtered_tokens']))
        for i in range(len(text_corpus)) for j in range(i+1, len(text_corpus))
    }
    
    print("Advanced comprehensions guide completed!")
    print(f"Graph metrics for node A: {graph_metrics['A']}")
    print(f"Document similarity example: {list(similarity_matrix.items())[0]}")
    ```

## ðŸŽ¯ Bonus: Performance Tips and Best Practices

??? question "Performance Optimization Guidelines"

    ```python
    # DO: Use generator expressions for memory efficiency
    large_data = range(1000000)
    
    # Memory efficient
    even_gen = (x for x in large_data if x % 2 == 0)
    
    # Memory intensive
    even_list = [x for x in large_data if x % 2 == 0]
    
    # DO: Use built-in functions when possible
    # Fast
    squares_builtin = list(map(lambda x: x**2, range(100)))
    
    # Slower for simple operations
    squares_comp = [x**2 for x in range(100)]
    
    # DO: Minimize function calls in comprehensions
    words = ["hello", "world", "python"] * 1000
    
    # Efficient - call len once per word
    long_words_good = [word for word in words if len(word) > 4]
    
    # Less efficient - multiple attribute lookups
    # long_words_bad = [word for word in words if word.__len__() > 4]
    
    # DO: Use set comprehensions for membership testing
    vowels = {'a', 'e', 'i', 'o', 'u'}  # Fast lookup
    text = "hello world"
    vowel_chars = [char for char in text if char in vowels]  # O(1) lookup
    
    # DON'T: Use list for membership testing
    vowels_list = ['a', 'e', 'i', 'o', 'u']  # Slow lookup
    # vowel_chars_slow = [char for char in text if char in vowels_list]  # O(n) lookup
    ```

## ðŸ“Š Summary of Key Concepts

This comprehensive guide covers:

1. **List Comprehensions**: Basic to advanced filtering, transformation, and flattening
2. **Dictionary Comprehensions**: Key-value mapping, grouping, and complex transformations  
3. **Set Comprehensions**: Unique value operations and mathematical set operations
4. **Nested Comprehensions**: Multi-dimensional data processing and complex algorithms

### Built-in Functions Integration:
- **lambda**: Anonymous functions for custom operations
- **map()**: Apply function to iterables
- **filter()**: Filter elements based on conditions
- **zip()**: Combine multiple iterables
- **enumerate()**: Add indices to iterations  
- **any()/all()**: Boolean operations on iterables
- **sorted()**: Sort with custom key functions
- **sum()/max()/min()**: Aggregation operations
- **Counter**: Frequency counting
- **itertools**: Advanced iteration patterns

### Performance Considerations:
- Use generators for memory efficiency
- Prefer built-ins for simple operations
- Minimize function calls in loops
- Use appropriate data structures (sets for membership testing)
- Consider readability vs. performance trade-offs