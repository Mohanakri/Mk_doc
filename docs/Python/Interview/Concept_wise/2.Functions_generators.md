# Python Functions & Generators Interview Questions - Complete Guide

## 📚 Table of Contents

### Function Basics Questions
### Scope Questions  
### Arguments Questions
### Advanced Functions Questions
### Comprehensions Questions
### Generator Questions
### Benchmarking Questions

---

## 🔧 Function Basics Questions

??? question "Q1: How do you define a basic function in Python and what are its components?"

    ```python
    # Basic function definition
    def greet(name):
        """This is a docstring - describes what the function does"""
        return f"Hello, {name}!"
    
    # Function with multiple parameters and default values
    def calculate_area(length, width=1):
        """Calculate area of rectangle with optional width parameter"""
        return length * width
    
    # Function without return statement (returns None)
    def print_message(message):
        print(message)
    
    # Usage examples
    print(greet("Alice"))           # Hello, Alice!
    print(calculate_area(5))        # 5 (width defaults to 1)
    print(calculate_area(5, 3))     # 15
    ```

??? question "Q2: What's the difference between parameters and arguments?"

    ```python
    # Parameters are in the function definition
    def add_numbers(x, y):  # x and y are parameters
        return x + y
    
    # Arguments are the actual values passed when calling
    result = add_numbers(3, 5)  # 3 and 5 are arguments
    
    # Example with different argument types
    def process_data(data, multiplier=2, debug=False):
        if debug:
            print(f"Processing: {data}")
        return data * multiplier
    
    # Positional arguments
    result1 = process_data(10)
    
    # Keyword arguments
    result2 = process_data(data=10, debug=True)
    
    # Mixed arguments
    result3 = process_data(10, multiplier=3, debug=True)
    ```

??? question "Q3: How do you create and use lambda functions?"

    ```python
    # Basic lambda function
    square = lambda x: x ** 2
    print(square(5))  # 25
    
    # Lambda with multiple parameters
    add = lambda x, y: x + y
    print(add(3, 4))  # 7
    
    # Using lambda with built-in functions
    numbers = [1, 2, 3, 4, 5]
    squared = list(map(lambda x: x**2, numbers))
    print(squared)  # [1, 4, 9, 16, 25]
    
    even_numbers = list(filter(lambda x: x % 2 == 0, numbers))
    print(even_numbers)  # [2, 4]
    
    # Sorting with lambda
    students = [('Alice', 85), ('Bob', 90), ('Charlie', 78)]
    students.sort(key=lambda x: x[1])  # Sort by grade
    print(students)  # [('Charlie', 78), ('Alice', 85), ('Bob', 90)]
    ```

---

## 🔍 Scope Questions

??? question "Q4: Explain the different types of variable scopes in Python"

    ```python
    # Global scope
    global_var = "I'm global"
    
    def outer_function():
        # Enclosing scope
        enclosing_var = "I'm in enclosing scope"
        
        def inner_function():
            # Local scope
            local_var = "I'm local"
            print(f"Local: {local_var}")
            print(f"Enclosing: {enclosing_var}")
            print(f"Global: {global_var}")
            # Built-in scope (like print, len, etc.)
            print(f"Built-in function: {len('hello')}")
        
        inner_function()
    
    outer_function()
    
    # LEGB Rule demonstration
    x = "global"
    
    def test_scope():
        x = "local"
        print(f"Inside function: {x}")
    
    test_scope()        # Inside function: local
    print(f"Outside: {x}")  # Outside: global
    ```

??? question "Q5: How do you use global and nonlocal keywords?"

    ```python
    # Global keyword example
    count = 0  # Global variable
    
    def increment_global():
        global count
        count += 1
        return count
    
    print(increment_global())  # 1
    print(increment_global())  # 2
    print(count)              # 2
    
    # Nonlocal keyword example
    def outer():
        x = 10
        
        def inner():
            nonlocal x
            x += 5
            return x
        
        def another_inner():
            # Without nonlocal, this creates a new local variable
            x = 100
            return x
        
        print(f"Before inner(): {x}")      # 10
        print(f"inner() returns: {inner()}")  # 15
        print(f"After inner(): {x}")       # 15
        print(f"another_inner(): {another_inner()}")  # 100
        print(f"x after another_inner(): {x}")  # 15
    
    outer()
    ```

??? question "Q6: What happens with mutable default arguments?"

    ```python
    # WRONG way - mutable default argument
    def append_to_list_wrong(item, target_list=[]):
        target_list.append(item)
        return target_list
    
    # This creates unexpected behavior
    list1 = append_to_list_wrong(1)
    list2 = append_to_list_wrong(2)
    print(list1)  # [1, 2] - NOT what we expected!
    print(list2)  # [1, 2] - Same list object!
    
    # CORRECT way - use None as default
    def append_to_list_correct(item, target_list=None):
        if target_list is None:
            target_list = []
        target_list.append(item)
        return target_list
    
    # Now it works as expected
    list3 = append_to_list_correct(1)
    list4 = append_to_list_correct(2)
    print(list3)  # [1]
    print(list4)  # [2]
    ```

---

## 📝 Arguments Questions

??? question "Q7: How do you handle variable-length arguments (*args and **kwargs)?"

    ```python
    # *args for variable positional arguments
    def sum_all(*args):
        return sum(args)
    
    print(sum_all(1, 2, 3))        # 6
    print(sum_all(1, 2, 3, 4, 5))  # 15
    
    # **kwargs for variable keyword arguments
    def print_info(**kwargs):
        for key, value in kwargs.items():
            print(f"{key}: {value}")
    
    print_info(name="Alice", age=30, city="New York")
    
    # Combining both
    def flexible_function(*args, **kwargs):
        print("Positional arguments:", args)
        print("Keyword arguments:", kwargs)
    
    flexible_function(1, 2, 3, name="Bob", age=25)
    
    # Unpacking arguments
    numbers = [1, 2, 3, 4]
    print(sum_all(*numbers))  # Unpacking list
    
    person_info = {"name": "Charlie", "age": 35}
    print_info(**person_info)  # Unpacking dictionary
    ```

??? question "Q8: What are keyword-only and positional-only arguments?"

    ```python
    # Positional-only arguments (Python 3.8+)
    def positional_only(a, b, /, c, d):
        """
        a and b are positional-only
        c and d can be positional or keyword
        """
        return a + b + c + d
    
    # Valid calls
    print(positional_only(1, 2, 3, 4))        # 10
    print(positional_only(1, 2, c=3, d=4))    # 10
    
    # Invalid: positional_only(a=1, b=2, c=3, d=4)  # TypeError
    
    # Keyword-only arguments
    def keyword_only(a, b, *, c, d):
        """
        a and b can be positional or keyword
        c and d are keyword-only
        """
        return a + b + c + d
    
    # Valid calls
    print(keyword_only(1, 2, c=3, d=4))       # 10
    print(keyword_only(a=1, b=2, c=3, d=4))   # 10
    
    # Invalid: keyword_only(1, 2, 3, 4)  # TypeError
    
    # Combining both (Python 3.8+)
    def mixed_args(pos_only, /, standard, *, kwd_only):
        return f"pos_only={pos_only}, standard={standard}, kwd_only={kwd_only}"
    
    print(mixed_args(1, 2, kwd_only=3))
    print(mixed_args(1, standard=2, kwd_only=3))
    ```

??? question "Q9: How do you use function annotations and type hints?"

    ```python
    from typing import List, Dict, Optional, Union
    
    # Basic type annotations
    def greet(name: str) -> str:
        return f"Hello, {name}!"
    
    def add_numbers(a: int, b: int) -> int:
        return a + b
    
    # Complex type annotations
    def process_scores(scores: List[float]) -> Dict[str, float]:
        return {
            "average": sum(scores) / len(scores),
            "max": max(scores),
            "min": min(scores)
        }
    
    # Optional and Union types
    def find_user(user_id: int) -> Optional[Dict[str, Union[str, int]]]:
        # Simulate database lookup
        users = {1: {"name": "Alice", "age": 30}}
        return users.get(user_id)
    
    # Function as parameter
    def apply_operation(numbers: List[int], 
                       operation: callable) -> List[int]:
        return [operation(n) for n in numbers]
    
    # Usage examples
    result = process_scores([85.5, 92.0, 78.5, 89.0])
    print(result)
    
    user = find_user(1)
    print(user)  # {'name': 'Alice', 'age': 30}
    
    squared = apply_operation([1, 2, 3, 4], lambda x: x**2)
    print(squared)  # [1, 4, 9, 16]
    ```

---

## 🚀 Advanced Functions Questions

??? question "Q10: How do you create and use decorators?"

    ```python
    # Basic decorator
    def timer_decorator(func):
        import time
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            print(f"{func.__name__} took {end_time - start_time:.4f} seconds")
            return result
        return wrapper
    
    @timer_decorator
    def slow_function():
        import time
        time.sleep(1)
        return "Done!"
    
    # Decorator with arguments
    def repeat(times):
        def decorator(func):
            def wrapper(*args, **kwargs):
                results = []
                for _ in range(times):
                    result = func(*args, **kwargs)
                    results.append(result)
                return results
            return wrapper
        return decorator
    
    @repeat(3)
    def greet(name):
        return f"Hello, {name}!"
    
    print(greet("Alice"))  # ['Hello, Alice!', 'Hello, Alice!', 'Hello, Alice!']
    
    # Class-based decorator
    class CountCalls:
        def __init__(self, func):
            self.func = func
            self.count = 0
        
        def __call__(self, *args, **kwargs):
            self.count += 1
            print(f"Call {self.count} of {self.func.__name__}")
            return self.func(*args, **kwargs)
    
    @CountCalls
    def say_hello():
        return "Hello!"
    
    say_hello()  # Call 1 of say_hello
    say_hello()  # Call 2 of say_hello
    ```

??? question "Q11: What are closures and how do they work?"

    ```python
    # Basic closure example
    def outer_function(x):
        # This is the enclosing scope
        
        def inner_function(y):
            # Inner function has access to outer function's variables
            return x + y  # x is from the enclosing scope
        
        return inner_function  # Return the inner function
    
    # Create closures
    add_10 = outer_function(10)
    add_20 = outer_function(20)
    
    print(add_10(5))  # 15 (10 + 5)
    print(add_20(5))  # 25 (20 + 5)
    
    # Closure with state
    def make_counter():
        count = 0
        
        def counter():
            nonlocal count
            count += 1
            return count
        
        return counter
    
    counter1 = make_counter()
    counter2 = make_counter()
    
    print(counter1())  # 1
    print(counter1())  # 2
    print(counter2())  # 1 (different closure, different state)
    print(counter1())  # 3
    
    # Practical closure example - configuration
    def make_multiplier(factor):
        def multiply(number):
            return number * factor
        return multiply
    
    double = make_multiplier(2)
    triple = make_multiplier(3)
    
    print(double(5))  # 10
    print(triple(5))  # 15
    ```

??? question "Q12: How do you implement function caching/memoization?"

    ```python
    from functools import lru_cache
    import time
    
    # Manual memoization
    def memoize(func):
        cache = {}
        
        def wrapper(*args):
            if args in cache:
                print(f"Cache hit for {args}")
                return cache[args]
            
            print(f"Computing for {args}")
            result = func(*args)
            cache[args] = result
            return result
        
        wrapper.cache = cache  # Expose cache for inspection
        return wrapper
    
    @memoize
    def fibonacci_manual(n):
        if n < 2:
            return n
        return fibonacci_manual(n-1) + fibonacci_manual(n-2)
    
    # Using built-in lru_cache
    @lru_cache(maxsize=None)
    def fibonacci_lru(n):
        if n < 2:
            return n
        return fibonacci_lru(n-1) + fibonacci_lru(n-2)
    
    # Performance comparison
    def time_function(func, *args):
        start = time.time()
        result = func(*args)
        end = time.time()
        return result, end - start
    
    # Test both implementations
    result1, time1 = time_function(fibonacci_manual, 35)
    result2, time2 = time_function(fibonacci_lru, 35)
    
    print(f"Manual memoization: {result1} in {time1:.4f} seconds")
    print(f"LRU cache: {result2} in {time2:.4f} seconds")
    
    # Cache information
    print(f"LRU cache info: {fibonacci_lru.cache_info()}")
    ```

---

## 📊 Comprehensions Questions

??? question "Q13: How do you use list, dict, and set comprehensions effectively?"

    ```python
    # List comprehensions
    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    
    # Basic list comprehension
    squares = [x**2 for x in numbers]
    print(squares)  # [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
    
    # With condition
    even_squares = [x**2 for x in numbers if x % 2 == 0]
    print(even_squares)  # [4, 16, 36, 64, 100]
    
    # Nested list comprehension
    matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    flattened = [num for row in matrix for num in row]
    print(flattened)  # [1, 2, 3, 4, 5, 6, 7, 8, 9]
    
    # Dictionary comprehensions
    word = "hello"
    char_count = {char: word.count(char) for char in word}
    print(char_count)  # {'h': 1, 'e': 1, 'l': 2, 'o': 1}
    
    # Dictionary with condition
    squared_evens = {x: x**2 for x in numbers if x % 2 == 0}
    print(squared_evens)  # {2: 4, 4: 16, 6: 36, 8: 64, 10: 100}
    
    # Set comprehensions
    unique_lengths = {len(word) for word in ["hello", "world", "python", "hi"]}
    print(unique_lengths)  # {2, 5, 6}
    
    # Complex example: group words by length
    words = ["apple", "banana", "cherry", "date", "elderberry"]
    word_groups = {length: [word for word in words if len(word) == length] 
                   for length in {len(word) for word in words}}
    print(word_groups)
    ```

??? question "Q14: When should you use comprehensions vs traditional loops?"

    ```python
    import time
    
    # Performance comparison
    def compare_methods():
        data = range(100000)
        
        # Traditional loop
        start = time.time()
        result1 = []
        for x in data:
            if x % 2 == 0:
                result1.append(x**2)
        time1 = time.time() - start
        
        # List comprehension
        start = time.time()
        result2 = [x**2 for x in data if x % 2 == 0]
        time2 = time.time() - start
        
        # Generator expression
        start = time.time()
        result3 = list(x**2 for x in data if x % 2 == 0)
        time3 = time.time() - start
        
        print(f"Traditional loop: {time1:.4f}s")
        print(f"List comprehension: {time2:.4f}s")
        print(f"Generator expression: {time3:.4f}s")
        
        return len(result1), len(result2), len(result3)
    
    compare_methods()
    
    # When to use each approach
    
    # Use comprehensions for:
    # 1. Simple transformations
    simple_transform = [x.upper() for x in ["hello", "world"]]
    
    # 2. Filtering
    positive_numbers = [x for x in [-2, -1, 0, 1, 2] if x > 0]
    
    # Use traditional loops for:
    # 1. Complex logic
    def complex_processing(data):
        results = []
        for item in data:
            if len(item) > 3:
                processed = item.upper()
                if processed.startswith('P'):
                    # Complex processing here
                    processed = processed + "_SPECIAL"
                results.append(processed)
        return results
    
    # 2. Multiple operations or side effects
    def process_with_logging(data):
        results = []
        for item in data:
            print(f"Processing: {item}")  # Side effect
            result = item * 2
            results.append(result)
            print(f"Result: {result}")    # Another side effect
        return results
    ```

---

## ⚡ Generator Questions

??? question "Q15: What are generators and how do they differ from regular functions?"

    ```python
    # Regular function that returns a list
    def squares_list(n):
        result = []
        for i in range(n):
            result.append(i**2)
        return result
    
    # Generator function using yield
    def squares_generator(n):
        for i in range(n):
            yield i**2
    
    # Memory usage comparison
    import sys
    
    list_squares = squares_list(1000)
    gen_squares = squares_generator(1000)
    
    print(f"List size: {sys.getsizeof(list_squares)} bytes")
    print(f"Generator size: {sys.getsizeof(gen_squares)} bytes")
    
    # Generator usage
    for square in gen_squares:
        if square > 100:
            print(f"First square > 100: {square}")
            break
    
    # Generator expressions
    gen_exp = (x**2 for x in range(10))
    print(list(gen_exp))  # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
    
    # Generator with state
    def fibonacci_generator():
        a, b = 0, 1
        while True:
            yield a
            a, b = b, a + b
    
    fib = fibonacci_generator()
    for i, num in enumerate(fib):
        if i >= 10:
            break
        print(num, end=" ")  # 0 1 1 2 3 5 8 13 21 34
    ```

??? question "Q16: How do you use generator methods (send, throw, close)?"

    ```python
    # Generator with send() method
    def echo_generator():
        value = None
        while True:
            value = yield value
            if value is not None:
                value = f"Echo: {value}"
    
    gen = echo_generator()
    next(gen)  # Prime the generator
    print(gen.send("Hello"))    # Echo: Hello
    print(gen.send("World"))    # Echo: World
    
    # Generator with throw() method
    def error_handling_generator():
        try:
            while True:
                value = yield
                print(f"Received: {value}")
        except ValueError as e:
            print(f"Caught error: {e}")
            yield "Error handled"
    
    gen = error_handling_generator()
    next(gen)
    gen.send("Normal value")
    
    try:
        gen.throw(ValueError, "Something went wrong")
        print(next(gen))  # Error handled
    except StopIteration:
        print("Generator ended")
    
    # Generator with close() method
    def resource_generator():
        print("Setting up resource")
        try:
            while True:
                yield "resource data"
        finally:
            print("Cleaning up resource")
    
    gen = resource_generator()
    print(next(gen))  # Setting up resource, resource data
    gen.close()       # Cleaning up resource
    
    # Practical example: coroutine-style generator
    def moving_average():
        total = 0
        count = 0
        average = None
        
        while True:
            value = yield average
            if value is not None:
                total += value
                count += 1
                average = total / count
    
    avg_gen = moving_average()
    next(avg_gen)  # Prime the generator
    
    print(avg_gen.send(10))    # 10.0
    print(avg_gen.send(20))    # 15.0
    print(avg_gen.send(30))    # 20.0
    ```

??? question "Q17: How do you chain and combine generators?"

    ```python
    import itertools
    
    # Basic generator chaining
    def numbers(start, end):
        for i in range(start, end):
            yield i
    
    def squares(iterable):
        for num in iterable:
            yield num**2
    
    def even_only(iterable):
        for num in iterable:
            if num % 2 == 0:
                yield num
    
    # Chain generators together
    pipeline = even_only(squares(numbers(1, 11)))
    print(list(pipeline))  # [4, 16, 36, 64, 100]
    
    # Using itertools for advanced chaining
    
    # Chain multiple iterables
    gen1 = (x for x in range(3))
    gen2 = (x for x in range(3, 6))
    chained = itertools.chain(gen1, gen2)
    print(list(chained))  # [0, 1, 2, 3, 4, 5]
    
    # Cycle through values
    colors = itertools.cycle(['red', 'green', 'blue'])
    for i, color in enumerate(colors):
        if i >= 8:
            break
        print(color, end=" ")  # red green blue red green blue red green
    
    # Compress based on selectors
    data = [1, 2, 3, 4, 5]
    selectors = [1, 0, 1, 0, 1]
    filtered = itertools.compress(data, selectors)
    print(list(filtered))  # [1, 3, 5]
    
    # Group consecutive elements
    data = [1, 1, 2, 2, 2, 3, 1, 1]
    grouped = itertools.groupby(data)
    for key, group in grouped:
        print(f"{key}: {list(group)}")
    # 1: [1, 1]
    # 2: [2, 2, 2]
    # 3: [3]
    # 1: [1, 1]
    
    # Practical example: processing large files
    def read_file_lines(filename):
        """Generator to read file line by line"""
        try:
            with open(filename, 'r') as file:
                for line in file:
                    yield line.strip()
        except FileNotFoundError:
            # Demo with fake data
            fake_lines = [f"Line {i}" for i in range(5)]
            for line in fake_lines:
                yield line
    
    def filter_lines(lines, keyword):
        """Filter lines containing keyword"""
        for line in lines:
            if keyword in line:
                yield line
    
    def transform_lines(lines):
        """Transform lines to uppercase"""
        for line in lines:
            yield line.upper()
    
    # Create processing pipeline
    file_lines = read_file_lines("data.txt")
    filtered_lines = filter_lines(file_lines, "Line")
    transformed_lines = transform_lines(filtered_lines)
    
    for line in transformed_lines:
        print(line)
    ```

---

## ⏱️ Benchmarking Questions

??? question "Q18: How do you benchmark and profile Python functions?"

    ```python
    import time
    import timeit
    import cProfile
    import functools
    
    # Basic timing decorator
    def timing_decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            start = time.perf_counter()
            result = func(*args, **kwargs)
            end = time.perf_counter()
            print(f"{func.__name__} took {end - start:.6f} seconds")
            return result
        return wrapper
    
    @timing_decorator
    def slow_operation():
        time.sleep(0.1)
        return sum(range(10000))
    
    # Using timeit for accurate measurements
    def compare_implementations():
        # List comprehension vs loop
        list_comp = """
result = [x**2 for x in range(1000)]
"""
        
        traditional_loop = """
result = []
for x in range(1000):
    result.append(x**2)
"""
        
        # Time both approaches
        time_comp = timeit.timeit(list_comp, number=10000)
        time_loop = timeit.timeit(traditional_loop, number=10000)
        
        print(f"List comprehension: {time_comp:.6f} seconds")
        print(f"Traditional loop: {time_loop:.6f} seconds")
        print(f"Speedup: {time_loop / time_comp:.2f}x")
    
    compare_implementations()
    
    # Memory profiling function
    import sys
    
    def memory_usage(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Get memory before
            import tracemalloc
            tracemalloc.start()
            
            result = func(*args, **kwargs)
            
            # Get memory after
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            
            print(f"{func.__name__} memory usage:")
            print(f"  Current: {current / 1024:.2f} KB")
            print(f"  Peak: {peak / 1024:.2f} KB")
            
            return result
        return wrapper
    
    @memory_usage
    def memory_intensive_function():
        # Create a large list
        data = list(range(100000))
        # Process it
        result = sum(x**2 for x in data)
        return result
    
    memory_intensive_function()
    
    # Profiling with cProfile
    def profile_function(func, *args, **kwargs):
        """Profile a function call"""
        profiler = cProfile.Profile()
        profiler.enable()
        
        result = func(*args, **kwargs)
        
        profiler.disable()
        profiler.print_stats(sort='cumulative')
        return result
    
    # Example function to profile
    def complex_calculation():
        def fibonacci(n):
            if n <= 1:
                return n
            return fibonacci(n-1) + fibonacci(n-2)
        
        results = []
        for i in range(25):
            results.append(fibonacci(i))
        return results
    
    # Profile the function
    # profile_function(complex_calculation)  # Uncomment to see profiling output

??? question "Q19: How do you optimize function performance?"

    ```python
    import functools
    from typing import Any
    
    # Optimization techniques
    
    # 1. Memoization for recursive functions
    @functools.lru_cache(maxsize=None)
    def fibonacci_optimized(n):
        if n <= 1:
            return n
        return fibonacci_optimized(n-1) + fibonacci_optimized(n-2)
    
    # 2. Using built-in functions instead of loops
    def sum_squares_slow(numbers):
        result = 0
        for num in numbers:
            result += num ** 2
        return result
    
    def sum_squares_fast(numbers):
        return sum(num ** 2 for num in numbers)
    
    # 3. Early termination
    def find_first_even_slow(numbers):
        evens = [num for num in numbers if num % 2 == 0]
        return evens[0] if evens else None
    
    def find_first_even_fast(numbers):
        for num in numbers:
            if num % 2 == 0:
                return num
        return None
    
    # 4. Using appropriate data structures
    def search_in_list(items, target):
        return target in items  # O(n) for lists
    
    def search_in_set(items, target):
        items_set = set(items)
        return target in items_set  # O(1) for sets
    
    # 5. Avoiding repeated calculations
    def distance_slow(points):
        distances = []
        for i, point1 in enumerate(points):
            for j, point2 in enumerate(points):
                if i != j:
                    dist = ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5
                    distances.append(dist)
        return distances
    
    def distance_fast(points):
        distances = []
        n = len(points)
        for i in range(n):
            for j in range(i + 1, n):  # Avoid duplicate calculations
                point1, point2 = points[i], points[j]
                dist = ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5
                distances.append(dist)
        return distances
    
    # Performance comparison
    def benchmark_optimization():
        import time
        
        numbers = list(range(10000))
        points = [(i, i+1) for i in range(100)]
        
        # Test different approaches
        test_cases = [
            (sum_squares_slow, sum_squares_fast, numbers),
            (find_first_even_slow, find_first_even_fast, numbers),
            (lambda items, target: search_in_list(items, 9999), 
             lambda items, target: search_in_set(items, 9999), numbers, 9999)
        ]
        
        for slow_func, fast_func, *args in test_cases:
            # Time slow version
            start = time.perf_counter()
            result1 = slow_func(*args)
            time_slow = time.perf_counter() - start
            
            # Time fast version
            start = time.perf_counter()
            result2 = fast_func(*args)
            time_fast = time.perf_counter() - start
            
            print(f"{slow_func.__name__}: {time_slow:.6f}s")
            print(f"{fast_func.__name__}: {time_fast:.6f}s")
            print(f"Speedup: {time_slow / time_fast:.2f}x\n")
    
    # benchmark_optimization()  # Uncomment to run benchmark
    ```

??? question "Q20: How do you handle function performance testing and regression?"

    ```python
    import time
    import statistics
    import contextlib
    from typing import Callable, List, Dict, Any
    
    class PerformanceTester:
        def __init__(self):
            self.results: Dict[str, List[float]] = {}
            self.baselines: Dict[str, float] = {}
        
        @contextlib.contextmanager
        def timer(self, name: str):
            """Context manager for timing operations"""
            start = time.perf_counter()
            yield
            end = time.perf_counter()
            
            if name not in self.results:
                self.results[name] = []
            self.results[name].append(end - start)
        
        def benchmark_function(self, func: Callable, *args, 
                             iterations: int = 100, **kwargs) -> Dict[str, float]:
            """Benchmark a function multiple times"""
            times = []
            
            for _ in range(iterations):
                start = time.perf_counter()
                func(*args, **kwargs)
                end = time.perf_counter()
                times.append(end - start)
            
            return {
                'mean': statistics.mean(times),
                'median': statistics.median(times),
                'min': min(times),
                'max': max(times),
                'std': statistics.stdev(times) if len(times) > 1 else 0
            }
        
        def set_baseline(self, name: str, func: Callable, *args, **kwargs):
            """Set performance baseline for a function"""
            result = self.benchmark_function(func, *args, **kwargs)
            self.baselines[name] = result['mean']
            print(f"Baseline set for {name}: {result['mean']:.6f}s")
        
        def test_regression(self, name: str, func: Callable, 
                          threshold: float = 1.2, *args, **kwargs):
            """Test for performance regression"""
            if name not in self.baselines:
                raise ValueError(f"No baseline set for {name}")
            
            result = self.benchmark_function(func, *args, **kwargs)
            current_time = result['mean']
            baseline_time = self.baselines[name]
            
            ratio = current_time / baseline_time
            
            print(f"Performance test for {name}:")
            print(f"  Baseline: {baseline_time:.6f}s")
            print(f"  Current:  {current_time:.6f}s")
            print(f"  Ratio:    {ratio:.2f}x")
            
            if ratio > threshold:
                print(f"  ❌ REGRESSION: {ratio:.2f}x slower than baseline!")
                return False
            else:
                print(f"  ✅ PASS: Within acceptable range")
                return True
    
    # Example usage
    def example_performance_testing():
        tester = PerformanceTester()
        
        # Test functions
        def bubble_sort(arr):
            n = len(arr)
            for i in range(n):
                for j in range(0, n - i - 1):
                    if arr[j] > arr[j + 1]:
                        arr[j], arr[j + 1] = arr[j + 1], arr[j]
            return arr
        
        def quick_sort(arr):
            if len(arr) <= 1:
                return arr
            pivot = arr[len(arr) // 2]
            left = [x for x in arr if x < pivot]
            middle = [x for x in arr if x == pivot]
            right = [x for x in arr if x > pivot]
            return quick_sort(left) + middle + quick_sort(right)
        
        # Test data
        test_data = [64, 34, 25, 12, 22, 11, 90, 5, 77, 30]
        
        # Set baselines
        tester.set_baseline("bubble_sort", bubble_sort, test_data.copy())
        tester.set_baseline("quick_sort", quick_sort, test_data.copy())
        
        # Test for regressions
        tester.test_regression("bubble_sort", bubble_sort, 1.5, test_data.copy())
        tester.test_regression("quick_sort", quick_sort, 1.5, test_data.copy())
        
        # Compare implementations
        bubble_stats = tester.benchmark_function(bubble_sort, test_data.copy())
        quick_stats = tester.benchmark_function(quick_sort, test_data.copy())
        
        print(f"\nBubble Sort Stats: {bubble_stats}")
        print(f"Quick Sort Stats: {quick_stats}")
        print(f"Quick Sort is {bubble_stats['mean'] / quick_stats['mean']:.2f}x faster")
    
    # example_performance_testing()  # Uncomment to run
    
    # Advanced profiling decorator
    def detailed_profiler(include_memory=False):
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                import tracemalloc
                
                if include_memory:
                    tracemalloc.start()
                
                start_time = time.perf_counter()
                start_cpu = time.process_time()
                
                result = func(*args, **kwargs)
                
                end_time = time.perf_counter()
                end_cpu = time.process_time()
                
                wall_time = end_time - start_time
                cpu_time = end_cpu - start_cpu
                
                print(f"\n📊 Performance Report for {func.__name__}:")
                print(f"   Wall time: {wall_time:.6f}s")
                print(f"   CPU time:  {cpu_time:.6f}s")
                print(f"   CPU usage: {(cpu_time/wall_time)*100:.1f}%")
                
                if include_memory:
                    current, peak = tracemalloc.get_traced_memory()
                    tracemalloc.stop()
                    print(f"   Memory current: {current/1024:.2f} KB")
                    print(f"   Memory peak:    {peak/1024:.2f} KB")
                
                return result
            return wrapper
        return decorator
    
    @detailed_profiler(include_memory=True)
    def example_function():
        # Simulate some work
        data = [i**2 for i in range(10000)]
        return sum(data)
    
    # example_function()  # Uncomment to see detailed profiling
    ```

---

## 🎯 Bonus: Real-World Function Patterns

??? question "Q21: How do you implement common function patterns?"

    ```python
    from functools import wraps, partial
    from typing import Callable, Any, TypeVar, Generic
    import asyncio
    
    # 1. Retry Pattern
    def retry(max_attempts: int = 3, delay: float = 1.0, 
             exceptions: tuple = (Exception,)):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                for attempt in range(max_attempts):
                    try:
                        return func(*args, **kwargs)
                    except exceptions as e:
                        if attempt == max_attempts - 1:
                            raise e
                        print(f"Attempt {attempt + 1} failed: {e}")
                        time.sleep(delay)
                return None
            return wrapper
        return decorator
    
    @retry(max_attempts=3, delay=0.5)
    def unreliable_function():
        import random
        if random.random() < 0.7:
            raise ConnectionError("Network error")
        return "Success!"
    
    # 2. Cache with TTL (Time To Live)
    import time
    from typing import Dict, Tuple
    
    def ttl_cache(ttl_seconds: int = 300):  # 5 minutes default
        def decorator(func):
            cache: Dict[tuple, Tuple[Any, float]] = {}
            
            @wraps(func)
            def wrapper(*args, **kwargs):
                key = args + tuple(sorted(kwargs.items()))
                current_time = time.time()
                
                if key in cache:
                    result, timestamp = cache[key]
                    if current_time - timestamp < ttl_seconds:
                        return result
                    else:
                        del cache[key]  # Remove expired entry
                
                result = func(*args, **kwargs)
                cache[key] = (result, current_time)
                return result
            
            wrapper.cache_clear = lambda: cache.clear()
            wrapper.cache_info = lambda: {'size': len(cache), 'ttl': ttl_seconds}
            return wrapper
        return decorator
    
    @ttl_cache(ttl_seconds=10)
    def expensive_api_call(endpoint: str):
        print(f"Making API call to {endpoint}")
        time.sleep(1)  # Simulate network delay
        return f"Data from {endpoint}"
    
    # 3. Rate Limiter
    from collections import defaultdict, deque
    
    def rate_limit(calls_per_second: int = 5):
        def decorator(func):
            call_times = defaultdict(deque)
            
            @wraps(func)
            def wrapper(*args, **kwargs):
                now = time.time()
                func_id = id(func)  # Unique identifier for this function
                
                # Remove calls older than 1 second
                while (call_times[func_id] and 
                       now - call_times[func_id][0] > 1):
                    call_times[func_id].popleft()
                
                # Check if we've exceeded the rate limit
                if len(call_times[func_id]) >= calls_per_second:
                    sleep_time = 1 - (now - call_times[func_id][0])
                    if sleep_time > 0:
                        time.sleep(sleep_time)
                        now = time.time()
                
                call_times[func_id].append(now)
                return func(*args, **kwargs)
            
            return wrapper
        return decorator
    
    @rate_limit(calls_per_second=2)
    def api_request(data):
        print(f"Processing: {data} at {time.time():.2f}")
        return f"Processed: {data}"
    
    # 4. Circuit Breaker Pattern
    class CircuitBreaker:
        def __init__(self, failure_threshold: int = 5, 
                     timeout: int = 60):
            self.failure_threshold = failure_threshold
            self.timeout = timeout
            self.failure_count = 0
            self.last_failure_time = None
            self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
        
        def __call__(self, func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                if self.state == 'OPEN':
                    if (time.time() - self.last_failure_time) > self.timeout:
                        self.state = 'HALF_OPEN'
                    else:
                        raise Exception("Circuit breaker is OPEN")
                
                try:
                    result = func(*args, **kwargs)
                    if self.state == 'HALF_OPEN':
                        self.state = 'CLOSED'
                        self.failure_count = 0
                    return result
                
                except Exception as e:
                    self.failure_count += 1
                    self.last_failure_time = time.time()
                    
                    if self.failure_count >= self.failure_threshold:
                        self.state = 'OPEN'
                    
                    raise e
            
            return wrapper
    
    @CircuitBreaker(failure_threshold=3, timeout=10)
    def flaky_service():
        import random
        if random.random() < 0.8:  # 80% failure rate
            raise Exception("Service unavailable")
        return "Service response"
    
    # 5. Partial Function Application
    def create_validator(min_length: int, max_length: int, 
                        allowed_chars: str = None):
        def validate(text: str) -> bool:
            if not (min_length <= len(text) <= max_length):
                return False
            
            if allowed_chars and not all(c in allowed_chars for c in text):
                return False
            
            return True
        
        return validate
    
    # Create specific validators
    username_validator = create_validator(3, 20, 
                                        "abcdefghijklmnopqrstuvwxyz0123456789_")
    email_validator = create_validator(5, 254)
    
    # Using partial for configuration
    from functools import partial
    
    def send_notification(message: str, priority: str = "normal", 
                         channel: str = "email"):
        return f"[{priority.upper()}] {message} -> {channel}"
    
    # Create specialized notification functions
    urgent_email = partial(send_notification, priority="urgent", channel="email")
    slack_notification = partial(send_notification, channel="slack")
    
    print(urgent_email("System down!"))        # [URGENT] System down! -> email
    print(slack_notification("Deploy complete"))  # [NORMAL] Deploy complete -> slack
    ```

??? question "Q22: How do you implement function composition and pipeline patterns?"

    ```python
    from functools import reduce
    from typing import Callable, Any, List
    
    # Function Composition
    def compose(*functions):
        """Compose functions right to left (mathematical style)"""
        return reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)
    
    def pipe(*functions):
        """Pipe functions left to right (more intuitive)"""
        return reduce(lambda f, g: lambda x: g(f(x)), functions, lambda x: x)
    
    # Example functions for composition
    def add_ten(x):
        return x + 10
    
    def multiply_by_two(x):
        return x * 2
    
    def to_string(x):
        return str(x)
    
    # Traditional approach
    def process_traditional(x):
        result = add_ten(x)
        result = multiply_by_two(result)
        result = to_string(result)
        return result
    
    # Composition approach
    process_composed = compose(to_string, multiply_by_two, add_ten)
    process_piped = pipe(add_ten, multiply_by_two, to_string)
    
    print(process_traditional(5))  # "30"
    print(process_composed(5))     # "30"
    print(process_piped(5))        # "30"
    
    # Advanced Pipeline Class
    class Pipeline:
        def __init__(self, *functions):
            self.functions = functions
        
        def __call__(self, value):
            return reduce(lambda acc, func: func(acc), self.functions, value)
        
        def __or__(self, other):
            """Allow using | operator for chaining"""
            if callable(other):
                return Pipeline(*self.functions, other)
            elif isinstance(other, Pipeline):
                return Pipeline(*self.functions, *other.functions)
            return NotImplemented
        
        def map(self, iterable):
            """Apply pipeline to each item in iterable"""
            return [self(item) for item in iterable]
        
        def filter(self, predicate):
            """Add a filter step to the pipeline"""
            return Pipeline(*self.functions, lambda x: x if predicate(x) else None)
    
    # Create reusable pipelines
    text_processor = Pipeline(
        str.strip,
        str.lower,
        lambda s: s.replace(' ', '_')
    )
    
    number_processor = Pipeline(
        lambda x: x * 2,
        lambda x: x + 1,
        lambda x: x ** 2
    )
    
    # Test pipelines
    texts = ["  Hello World  ", "  Python Rocks  "]
    numbers = [1, 2, 3, 4, 5]
    
    print(text_processor.map(texts))      # ['hello_world', 'python_rocks']
    print(number_processor.map(numbers))  # [9, 25, 49, 81, 121]
    
    # Chaining pipelines with | operator
    combined = text_processor | (lambda s: s.upper())
    print(combined("  hello world  "))  # HELLO_WORLD
    
    # Data Processing Pipeline Example
    def clean_data(data):
        """Remove None and empty values"""
        return [item for item in data if item is not None and item != ""]
    
    def normalize_strings(data):
        """Convert all items to lowercase strings"""
        return [str(item).lower() for item in data]
    
    def remove_duplicates(data):
        """Remove duplicate values while preserving order"""
        seen = set()
        return [item for item in data if not (item in seen or seen.add(item))]
    
    def sort_data(data):
        """Sort the data"""
        return sorted(data)
    
    # Create data processing pipeline
    data_pipeline = Pipeline(
        clean_data,
        normalize_strings,
        remove_duplicates,
        sort_data
    )
    
    # Test with messy data
    messy_data = ["Apple", None, "banana", "", "Apple", "Cherry", 123, "banana"]
    cleaned_data = data_pipeline(messy_data)
    print(cleaned_data)  # ['123', 'apple', 'banana', 'cherry']
    
    # Async Pipeline (bonus)
    import asyncio
    
    class AsyncPipeline:
        def __init__(self, *functions):
            self.functions = functions
        
        async def __call__(self, value):
            result = value
            for func in self.functions:
                if asyncio.iscoroutinefunction(func):
                    result = await func(result)
                else:
                    result = func(result)
            return result
    
    # Example async functions
    async def async_fetch_data(url):
        await asyncio.sleep(0.1)  # Simulate network delay
        return f"Data from {url}"
    
    async def async_process_data(data):
        await asyncio.sleep(0.1)  # Simulate processing time
        return data.upper()
    
    def sync_finalize(data):
        return f"[FINAL] {data}"
    
    # Create async pipeline
    async_pipeline = AsyncPipeline(
        async_fetch_data,
        async_process_data,
        sync_finalize
    )
    
    # Usage (uncomment to test)
    # async def test_async_pipeline():
    #     result = await async_pipeline("https://api.example.com")
    #     print(result)  # [FINAL] DATA FROM HTTPS://API.EXAMPLE.COM
    #
    # asyncio.run(test_async_pipeline())
    ```

---

## 🏆 Summary and Best Practices

### Key Takeaways:

1. **Function Design**: Keep functions small, focused, and pure when possible
2. **Scope Management**: Understand LEGB rule and use `global`/`nonlocal` judiciously  
3. **Arguments**: Master *args, **kwargs, and type hints for flexible APIs
4. **Performance**: Use appropriate data structures, memoization, and profiling
5. **Generators**: Prefer memory-efficient generators for large datasets
6. **Patterns**: Learn common patterns like decorators, closures, and pipelines

### Interview Tips:

- Always consider edge cases and error handling
- Discuss time and space complexity
- Show multiple implementation approaches
- Explain trade-offs between solutions
- Use meaningful variable names and add docstrings
- Demonstrate knowledge of Python idioms and best practices

---

*This guide covers fundamental to advanced function concepts in Python. Practice these patterns and understand their use cases for better code design and interview success!* 🚀