# Python Dictionary Interview Questions - Complete Guide

## 📚 Table of Contents
- [Basic Dictionary Operations (Questions 1-15)](#-basic-dictionary-operations)
- [Dictionary Manipulation & Transformation (Questions 16-30)](#-dictionary-manipulation--transformation)
- [Advanced Dictionary Algorithms (Questions 31-45)](#-advanced-dictionary-algorithms)
- [Real-world Applications (Questions 46-60)](#-real-world-applications)

---

## 🔧 Basic Dictionary Operations

??? question "Q1: How do you sort a dictionary by values (ascending/descending)?"
    ```python
    def sort_dict_by_value(d, reverse=False):
        return dict(sorted(d.items(), key=lambda x: x[1], reverse=reverse))
    
    # Example
    data = {'a': 3, 'b': 1, 'c': 2}
    print(sort_dict_by_value(data))  # {'b': 1, 'c': 2, 'a': 3}
    print(sort_dict_by_value(data, True))  # {'a': 3, 'c': 2, 'b': 1}
    ```

??? question "Q2: How do you merge multiple dictionaries with conflict resolution?"
    ```python
    def merge_dicts(*dicts, conflict_resolver=None):
        result = {}
        for d in dicts:
            for key, value in d.items():
                if key in result:
                    if conflict_resolver:
                        result[key] = conflict_resolver(key, result[key], value)
                    else:
                        result[key] = value  # Last wins
                else:
                    result[key] = value
        return result
    
    # Example with sum resolver
    d1 = {'a': 1, 'b': 2}
    d2 = {'b': 3, 'c': 4}
    d3 = {'a': 5, 'd': 6}
    
    result = merge_dicts(d1, d2, d3, conflict_resolver=lambda k, v1, v2: v1 + v2)
    print(result)  # {'a': 6, 'b': 5, 'c': 4, 'd': 6}
    ```

??? question "Q3: How do you check for key existence and handle missing keys?"
    ```python
    def safe_get_nested(d, keys, default=None):
        """Safely get nested dictionary values"""
        current = d
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return default
        return current
    
    # Example
    data = {'user': {'profile': {'name': 'John', 'age': 30}}}
    print(safe_get_nested(data, ['user', 'profile', 'name']))  # 'John'
    print(safe_get_nested(data, ['user', 'settings', 'theme'], 'dark'))  # 'dark'
    ```

??? question "Q4: How do you create a dictionary from two lists with duplicate handling?"
    ```python
    from collections import defaultdict
    
    def create_dict_from_lists(keys, values):
        """Create dict handling duplicate keys by collecting values in lists"""
        result = defaultdict(list)
        for k, v in zip(keys, values):
            result[k].append(v)
        return dict(result)
    
    # Example
    keys = ['a', 'b', 'a', 'c', 'b']
    values = [1, 2, 3, 4, 5]
    print(create_dict_from_lists(keys, values))
    # {'a': [1, 3], 'b': [2, 5], 'c': [4]}
    ```

??? question "Q5: How do you filter a dictionary by conditions on keys/values?"
    ```python
    def filter_dict(d, key_condition=None, value_condition=None):
        """Filter dictionary by conditions on keys and/or values"""
        result = {}
        for k, v in d.items():
            key_ok = key_condition(k) if key_condition else True
            value_ok = value_condition(v) if value_condition else True
            if key_ok and value_ok:
                result[k] = v
        return result
    
    # Example
    data = {'apple': 150, 'banana': 80, 'cherry': 200, 'date': 90}
    
    # Filter fruits with price > 100 and name length > 4
    filtered = filter_dict(data, 
                          key_condition=lambda k: len(k) > 4,
                          value_condition=lambda v: v > 100)
    print(filtered)  # {'apple': 150, 'cherry': 200}
    ```

---

## 🔄 Dictionary Manipulation & Transformation

??? question "Q6: How do you invert a dictionary with non-unique values?"
    ```python
    from collections import defaultdict
    
    def invert_dict_non_unique(d):
        """Invert dictionary handling non-unique values"""
        inverted = defaultdict(list)
        for key, value in d.items():
            inverted[value].append(key)
        return dict(inverted)
    
    # Example
    data = {'a': 1, 'b': 2, 'c': 1, 'd': 3, 'e': 2}
    print(invert_dict_non_unique(data))
    # {1: ['a', 'c'], 2: ['b', 'e'], 3: ['d']}
    ```

??? question "Q7: How do you flatten a nested dictionary?"
    ```python
    def flatten_dict(d, parent_key='', sep='_'):
        """Flatten nested dictionary with configurable separator"""
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(flatten_dict(v, new_key, sep).items())
            else:
                items.append((new_key, v))
        return dict(items)
    
    # Example
    nested = {
        'user': {
            'profile': {'name': 'John', 'age': 30},
            'settings': {'theme': 'dark'}
        },
        'status': 'active'
    }
    print(flatten_dict(nested))
    # {'user_profile_name': 'John', 'user_profile_age': 30, 
    #  'user_settings_theme': 'dark', 'status': 'active'}
    ```

??? question "Q8: How do you group dictionary items by a function?"
    ```python
    from collections import defaultdict
    import math
    
    def group_by_function(items, key_func):
        """Group dictionary items by applying function to values"""
        groups = defaultdict(list)
        for key, value in items.items():
            group_key = key_func(value)
            groups[group_key].append({key: value})
        return dict(groups)
    
    # Example - Group by value ranges
    data = {'a': 15, 'b': 25, 'c': 35, 'd': 45, 'e': 12}
    grouped = group_by_function(data, lambda x: x // 10 * 10)  # Group by decades
    print(grouped)
    # {10: [{'a': 15}, {'e': 12}], 20: [{'b': 25}], 
    #  30: [{'c': 35}], 40: [{'d': 45}]}
    ```

??? question "Q9: How do you transform dictionary values while preserving structure?"
    ```python
    def transform_dict_values(d, transform_func, recursive=False):
        """Transform dictionary values with optional recursion"""
        result = {}
        for key, value in d.items():
            if recursive and isinstance(value, dict):
                result[key] = transform_dict_values(value, transform_func, recursive)
            elif isinstance(value, list):
                result[key] = [transform_func(v) if not isinstance(v, dict) 
                              else transform_dict_values(v, transform_func, recursive) 
                              for v in value]
            else:
                result[key] = transform_func(value)
        return result
    
    # Example - Convert all strings to uppercase, numbers to squares
    def my_transform(value):
        if isinstance(value, str):
            return value.upper()
        elif isinstance(value, (int, float)):
            return value ** 2
        return value
    
    data = {
        'name': 'john',
        'age': 5,
        'scores': [3, 4, 5],
        'profile': {'city': 'ny', 'rating': 3}
    }
    
    transformed = transform_dict_values(data, my_transform, recursive=True)
    print(transformed)
    # {'name': 'JOHN', 'age': 25, 'scores': [9, 16, 25], 
    #  'profile': {'city': 'NY', 'rating': 9}}
    ```

??? question "Q10: How do you find the top N items by different criteria?"
    ```python
    import heapq
    from collections import Counter
    
    def get_top_n_items(d, n, criteria='value', reverse=True):
        """Get top N items by different criteria"""
        if criteria == 'value':
            items = heapq.nlargest(n, d.items(), key=lambda x: x[1]) if reverse \
                   else heapq.nsmallest(n, d.items(), key=lambda x: x[1])
        elif criteria == 'key_length':
            items = heapq.nlargest(n, d.items(), key=lambda x: len(str(x[0]))) if reverse \
                   else heapq.nsmallest(n, d.items(), key=lambda x: len(str(x[0])))
        elif criteria == 'key_alphabetical':
            sorted_items = sorted(d.items(), key=lambda x: x[0], reverse=reverse)
            items = sorted_items[:n]
        else:
            raise ValueError("Invalid criteria")
        
        return dict(items)
    
    # Example
    data = {'apple': 150, 'banana': 80, 'cherry': 200, 'date': 90, 'elderberry': 120}
    
    print("Top 3 by value:", get_top_n_items(data, 3, 'value'))
    print("Top 3 by key length:", get_top_n_items(data, 3, 'key_length'))
    print("Top 3 alphabetically:", get_top_n_items(data, 3, 'key_alphabetical'))
    ```

---

## 🧠 Advanced Dictionary Algorithms

??? question "Q11: How do you implement a dictionary-based LRU cache?"
    ```python
    from collections import OrderedDict
    
    class LRUCache:
        def __init__(self, capacity):
            self.capacity = capacity
            self.cache = OrderedDict()
        
        def get(self, key):
            if key in self.cache:
                # Move to end (most recently used)
                self.cache.move_to_end(key)
                return self.cache[key]
            return -1
        
        def put(self, key, value):
            if key in self.cache:
                # Update existing key
                self.cache.move_to_end(key)
            elif len(self.cache) >= self.capacity:
                # Remove least recently used (first item)
                self.cache.popitem(last=False)
            
            self.cache[key] = value
        
        def __str__(self):
            return str(dict(self.cache))
    
    # Example usage
    lru = LRUCache(3)
    lru.put('a', 1)
    lru.put('b', 2)
    lru.put('c', 3)
    print(lru)  # {'a': 1, 'b': 2, 'c': 3}
    
    lru.get('a')  # Access 'a'
    lru.put('d', 4)  # This should evict 'b'
    print(lru)  # {'c': 3, 'a': 1, 'd': 4}
    ```

??? question "Q12: How do you implement a bidirectional dictionary?"
    ```python
    class BiDict:
        def __init__(self):
            self._forward = {}
            self._reverse = {}
        
        def __setitem__(self, key, value):
            # Remove existing mappings
            if key in self._forward:
                old_value = self._forward[key]
                del self._reverse[old_value]
            if value in self._reverse:
                old_key = self._reverse[value]
                del self._forward[old_key]
            
            # Set new mapping
            self._forward[key] = value
            self._reverse[value] = key
        
        def __getitem__(self, key):
            return self._forward[key]
        
        def get_by_value(self, value):
            return self._reverse[value]
        
        def __delitem__(self, key):
            value = self._forward[key]
            del self._forward[key]
            del self._reverse[value]
        
        def __contains__(self, key):
            return key in self._forward
        
        def value_in(self, value):
            return value in self._reverse
        
        def items(self):
            return self._forward.items()
        
        def __str__(self):
            return str(self._forward)
    
    # Example usage
    bd = BiDict()
    bd['name'] = 'John'
    bd['age'] = 30
    
    print(bd['name'])  # John
    print(bd.get_by_value('John'))  # name
    print('John' in bd)  # False
    print(bd.value_in('John'))  # True
    ```

??? question "Q13: How do you implement memoization with dictionary?"
    ```python
    import functools
    import hashlib
    import json
    
    def advanced_memoize(func):
        """Memoization decorator handling unhashable arguments"""
        cache = {}
        
        def make_key(*args, **kwargs):
            # Handle unhashable arguments by converting to JSON
            try:
                return (args, tuple(sorted(kwargs.items())))
            except TypeError:
                # Fallback for unhashable types
                serialized = json.dumps([args, kwargs], sort_keys=True, default=str)
                return hashlib.md5(serialized.encode()).hexdigest()
        
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            key = make_key(*args, **kwargs)
            if key not in cache:
                cache[key] = func(*args, **kwargs)
            return cache[key]
        
        wrapper.cache = cache
        wrapper.clear_cache = lambda: cache.clear()
        return wrapper
    
    # Example usage
    @advanced_memoize
    def expensive_function(data_list, config_dict):
        """Simulate expensive computation"""
        import time
        time.sleep(0.1)  # Simulate work
        return sum(data_list) * config_dict.get('multiplier', 1)
    
    # Test with unhashable arguments
    result1 = expensive_function([1, 2, 3], {'multiplier': 2})  # Computed
    result2 = expensive_function([1, 2, 3], {'multiplier': 2})  # Cached
    print(f"Results: {result1}, {result2}")
    print(f"Cache size: {len(expensive_function.cache)}")
    ```

??? question "Q14: How do you implement a dictionary-based graph with algorithms?"
    ```python
    import heapq
    from collections import defaultdict, deque
    
    class Graph:
        def __init__(self):
            self.graph = defaultdict(dict)  # {node: {neighbor: weight}}
        
        def add_edge(self, u, v, weight=1):
            self.graph[u][v] = weight
        
        def dijkstra(self, start, end):
            """Find shortest path using Dijkstra's algorithm"""
            distances = {node: float('inf') for node in self.graph}
            distances[start] = 0
            pq = [(0, start)]
            previous = {}
            
            while pq:
                current_dist, current = heapq.heappop(pq)
                
                if current == end:
                    # Reconstruct path
                    path = []
                    while current in previous:
                        path.append(current)
                        current = previous[current]
                    path.append(start)
                    return path[::-1], distances[end]
                
                if current_dist > distances[current]:
                    continue
                
                for neighbor, weight in self.graph[current].items():
                    distance = current_dist + weight
                    if distance < distances[neighbor]:
                        distances[neighbor] = distance
                        previous[neighbor] = current
                        heapq.heappush(pq, (distance, neighbor))
            
            return None, float('inf')
        
        def has_cycle(self):
            """Detect cycle using DFS"""
            color = {}  # 0: white, 1: gray, 2: black
            
            def dfs(node):
                if node in color:
                    return color[node] == 1  # Gray node = cycle
                
                color[node] = 1  # Mark as gray
                for neighbor in self.graph[node]:
                    if dfs(neighbor):
                        return True
                
                color[node] = 2  # Mark as black
                return False
            
            for node in self.graph:
                if node not in color and dfs(node):
                    return True
            return False
    
    # Example usage
    g = Graph()
    g.add_edge('A', 'B', 4)
    g.add_edge('A', 'C', 2)
    g.add_edge('B', 'C', 1)
    g.add_edge('B', 'D', 5)
    g.add_edge('C', 'D', 8)
    
    path, distance = g.dijkstra('A', 'D')
    print(f"Shortest path from A to D: {path}, distance: {distance}")
    print(f"Has cycle: {g.has_cycle()}")
    ```

??? question "Q15: How do you handle dictionary serialization with circular references?"
    ```python
    import json
    import uuid
    
    def serialize_with_circular_refs(obj):
        """Serialize dictionary with circular reference handling"""
        seen = {}
        refs = {}
        
        def replace_circular(item, path="root"):
            if isinstance(item, dict):
                # Check if we've seen this exact dict object
                obj_id = id(item)
                if obj_id in seen:
                    # Create reference
                    if obj_id not in refs:
                        refs[obj_id] = f"__ref_{len(refs)}"
                    return {"__circular_ref": refs[obj_id]}
                
                seen[obj_id] = path
                result = {}
                for key, value in item.items():
                    result[key] = replace_circular(value, f"{path}.{key}")
                return result
            
            elif isinstance(item, list):
                return [replace_circular(v, f"{path}[{i}]") for i, v in enumerate(item)]
            
            return item
        
        # First pass: identify and replace circular references
        clean_obj = replace_circular(obj)
        
        # Create reference table
        ref_table = {ref_id: seen[obj_id] for obj_id, ref_id in refs.items()}
        
        return {
            "data": clean_obj,
            "references": ref_table
        }
    
    def deserialize_with_circular_refs(serialized):
        """Deserialize dictionary restoring circular references"""
        data = serialized["data"]
        ref_table = serialized["references"]
        
        # Find all circular references
        circular_refs = {}
        
        def find_refs(obj, path="root"):
            if isinstance(obj, dict):
                if "__circular_ref" in obj:
                    circular_refs[path] = obj["__circular_ref"]
                    return None
                else:
                    for key, value in obj.items():
                        find_refs(value, f"{path}.{key}")
            elif isinstance(obj, list):
                for i, value in enumerate(obj):
                    find_refs(value, f"{path}[{i}]")
        
        find_refs(data)
        
        # TODO: Implement reference restoration logic
        # This is a simplified version - full implementation would restore references
        return data
    
    # Example usage
    a = {'name': 'A'}
    b = {'name': 'B', 'friend': a}
    a['friend'] = b  # Create circular reference
    
    try:
        # This would fail with regular JSON
        # json.dumps(a)
        serialized = serialize_with_circular_refs(a)
        print("Serialized with circular refs:", json.dumps(serialized, indent=2))
    except Exception as e:
        print(f"Error: {e}")
    ```

---

## 🌍 Real-world Applications

??? question "Q16: How do you build a word frequency analyzer with ranking?"
    ```python
    import re
    from collections import Counter, defaultdict
    import heapq
    
    class TextAnalyzer:
        def __init__(self):
            self.word_freq = Counter()
            self.char_freq = Counter()
            self.sentence_count = 0
            self.word_positions = defaultdict(list)
        
        def analyze_text(self, text):
            """Comprehensive text analysis"""
            # Clean and tokenize
            sentences = re.split(r'[.!?]+', text)
            self.sentence_count = len([s for s in sentences if s.strip()])
            
            words = re.findall(r'\b\w+\b', text.lower())
            
            # Count frequencies
            self.word_freq.update(words)
            self.char_freq.update(text.lower())
            
            # Track positions
            for i, word in enumerate(words):
                self.word_positions[word].append(i)
        
        def get_top_words(self, n=10, min_length=1):
            """Get top N words with filters"""
            filtered_words = {word: count for word, count in self.word_freq.items() 
                            if len(word) >= min_length}
            return dict(Counter(filtered_words).most_common(n))
        
        def get_word_stats(self):
            """Get comprehensive statistics"""
            total_words = sum(self.word_freq.values())
            unique_words = len(self.word_freq)
            avg_word_length = sum(len(word) * count for word, count in self.word_freq.items()) / total_words
            
            return {
                'total_words': total_words,
                'unique_words': unique_words,
                'vocabulary_richness': unique_words / total_words,
                'average_word_length': round(avg_word_length, 2),
                'sentences': self.sentence_count,
                'words_per_sentence': round(total_words / max(self.sentence_count, 1), 2)
            }
        
        def find_similar_frequency_words(self, target_word, tolerance=0.1):
            """Find words with similar frequency to target word"""
            if target_word not in self.word_freq:
                return []
            
            target_freq = self.word_freq[target_word]
            similar = []
            
            for word, freq in self.word_freq.items():
                if word != target_word:
                    freq_ratio = abs(freq - target_freq) / target_freq
                    if freq_ratio <= tolerance:
                        similar.append((word, freq))
            
            return sorted(similar, key=lambda x: abs(x[1] - target_freq))
    
    # Example usage
    analyzer = TextAnalyzer()
    text = """
    The quick brown fox jumps over the lazy dog. The dog was very lazy.
    Quick brown foxes are known for jumping. Dogs are often lazy in the afternoon.
    """
    
    analyzer.analyze_text(text)
    print("Top words:", analyzer.get_top_words(5))
    print("Stats:", analyzer.get_word_stats())
    print("Similar to 'the':", analyzer.find_similar_frequency_words('the'))
    ```

??? question "Q17: How do you implement a configuration manager with nested settings?"
    ```python
    import json
    import os
    from typing import Any, Dict, Optional
    
    class ConfigManager:
        def __init__(self, config_file: str = None):
            self.config = {}
            self.defaults = {}
            self.config_file = config_file
            if config_file and os.path.exists(config_file):
                self.load_from_file(config_file)
        
        def set_defaults(self, defaults: Dict[str, Any]):
            """Set default configuration values"""
            self.defaults.update(defaults)
        
        def get(self, key_path: str, default: Any = None) -> Any:
            """Get configuration value using dot notation"""
            keys = key_path.split('.')
            current = self.config
            
            # Try to get from config first
            for key in keys:
                if isinstance(current, dict) and key in current:
                    current = current[key]
                else:
                    # Fall back to defaults
                    current = self.defaults
                    for key in keys:
                        if isinstance(current, dict) and key in current:
                            current = current[key]
                        else:
                            return default
                    break
            
            return current
        
        def set(self, key_path: str, value: Any):
            """Set configuration value using dot notation"""
            keys = key_path.split('.')
            current = self.config
            
            # Navigate to parent
            for key in keys[:-1]:
                if key not in current:
                    current[key] = {}
                current = current[key]
            
            # Set final value
            current[keys[-1]] = value
        
        def merge_config(self, new_config: Dict[str, Any]):
            """Deep merge new configuration"""
            def deep_merge(base, new):
                for key, value in new.items():
                    if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                        deep_merge(base[key], value)
                    else:
                        base[key] = value
            
            deep_merge(self.config, new_config)
        
        def get_environment_overrides(self, prefix: str = "APP_"):
            """Get configuration overrides from environment variables"""
            overrides = {}
            for key, value in os.environ.items():
                if key.startswith(prefix):
                    # Convert APP_DATABASE_HOST to database.host
                    config_key = key[len(prefix):].lower().replace('_', '.')
                    
                    # Try to parse as JSON, fall back to string
                    try:
                        parsed_value = json.loads(value)
                    except (json.JSONDecodeError, ValueError):
                        parsed_value = value
                    
                    self.set(config_key, parsed_value)
        
        def save_to_file(self, filename: str = None):
            """Save configuration to file"""
            filename = filename or self.config_file
            if filename:
                with open(filename, 'w') as f:
                    json.dump(self.config, f, indent=2)
        
        def load_from_file(self, filename: str):
            """Load configuration from file"""
            with open(filename, 'r') as f:
                loaded_config = json.load(f)
                self.merge_config(loaded_config)
        
        def validate_required(self, required_keys: list) -> list:
            """Validate that required configuration keys are present"""
            missing = []
            for key in required_keys:
                if self.get(key) is None:
                    missing.append(key)
            return missing
        
        def __repr__(self):
            return f"ConfigManager({json.dumps(self.config, indent=2)})"
    
    # Example usage
    config = ConfigManager()
    
    # Set defaults
    config.set_defaults({
        'database': {
            'host': 'localhost',
            'port': 5432,
            'name': 'myapp'
        },
        'api': {
            'timeout': 30,
            'retries': 3
        }
    })
    
    # Override specific values
    config.set('database.host', 'production.db')
    config.set('api.key', 'secret123')
    
    # Get values
    print("DB Host:", config.get('database.host'))  # production.db
    print("API Timeout:", config.get('api.timeout'))  # 30 (from defaults)
    print("Missing key:", config.get('cache.ttl', 3600))  # 3600 (default)
    
    # Validate required keys
    required = ['database.host', 'api.key', 'missing.key']
    missing = config.validate_required(required)
    print("Missing required keys:", missing)  # ['missing.key']
    ```

??? question "Q18: How do you implement a data aggregation pipeline with dictionaries?"
    ```python
    from collections import defaultdict, Counter
    from functools import reduce
    from typing import List, Dict, Any, Callable
    import statistics
    
    class DataAggregator:
        def __init__(self):
            self.aggregation_functions = {
                'sum': sum,
                'avg': statistics.mean,
                'median': statistics.median,
                'count': len,
                'min': min,
                'max': max,
                'std': statistics.stdev if statistics else lambda x: 0,
                'unique_count': lambda x: len(set(x))
            }
        
        def group_by(self, data: List[Dict[str, Any]], group_keys: List[str]) -> Dict[tuple, List[Dict]]:
            """Group data by specified keys"""
            groups = defaultdict(list)
            
            for item in data:
                # Create group key tuple
                group_key = tuple(item.get(key) for key in group_keys)
                groups[group_key].append(item)
            
            return dict(groups)
        
        def aggregate(self, data: List[Dict[str, Any]], 
                     group_by: List[str], 
                     aggregations: Dict[str, str]) -> List[Dict[str, Any]]:
            """Perform aggregation on grouped data"""
            
            # Group data
            groups = self.group_by(data, group_by)
            
            results = []
            for group_key, group_data in groups.items():
                result = {}
                
                # Add group key fields
                for i, key in enumerate(group_by):
                    result[key] = group_key[i]
                
                # Perform aggregations
                for field, agg_func in aggregations.items():
                    if agg_func in self.aggregation_functions:
                        values = [item[field] for item in group_data if field in item and item[field] is not None]
                        if values:
                            result[f"{field}_{agg_func}"] = self.aggregation_functions[agg_func](values)
                        else:
                            result[f"{field}_{agg_func}"] = None
                
                results.append(result)
            
            return results
        
        def pivot_table(self, data: List[Dict[str, Any]], 
                       index: str, columns: str, values: str, 
                       agg_func: str = 'sum') -> Dict[str, Dict[str, Any]]:
            """Create pivot table from data"""
            pivot = defaultdict(lambda: defaultdict(list))
            
            # Collect data
            for item in data:
                if all(key in item for key in [index, columns, values]):
                    pivot[item[index]][item[columns]].append(item[values])
            
            # Apply aggregation
            result = {}
            agg_function = self.aggregation_functions.get(agg_func, sum)
            
            for idx, cols in pivot.items():
                result[idx] = {}
                for col, vals in cols.items():
                    result[idx][col] = agg_function(vals) if vals else None
            
            return result
        
        def window_function(self, data: List[Dict[str, Any]], 
                           partition_by: List[str], 
                           order_by: str, 
                           window_func: str, 
                           target_field: str) -> List[Dict[str, Any]]:
            """Apply window function to data"""
            
            # Group by partition keys
            partitions = self.group_by(data, partition_by)
            
            result = []
            for partition_data in partitions.values():
                # Sort by order_by field
                sorted_data = sorted(partition_data, key=lambda x: x.get(order_by, 0))
                
                # Apply window function
                values = [item[target_field] for item in sorted_data if target_field in item]
                
                for i, item in enumerate(sorted_data):
                    new_item = item.copy()
                    
                    if window_func == 'row_number':
                        new_item[f"{target_field}_row_number"] = i + 1
                    elif window_func == 'rank':
                        # Simple ranking implementation
                        current_value = item.get(target_field)
                        rank = sum(1 for v in values[:i+1] if v <= current_value)
                        new_item[f"{target_field}_rank"] = rank
                    elif window_func == 'running_sum':
                        new_item[f"{target_field}_running_sum"] = sum(values[:i+1])
                    elif window_func == 'running_avg':
                        new_item[f"{target_field}_running_avg"] = sum(values[:i+1]) / (i + 1)
                    
                    result.append(new_item)
            
            return result
    
    # Example usage
    sales_data = [
        {'region': 'North', 'product': 'A', 'month': '2024-01', 'sales': 100, 'profit': 20},
        {'region': 'North', 'product': 'A', 'month': '2024-02', 'sales': 150, 'profit': 30},
        {'region': 'North', 'product': 'B', 'month': '2024-01', 'sales': 80, 'profit': 15},
        {'region': 'South', 'product': 'A', 'month': '2024-01', 'sales': 120, 'profit': 25},
        {'region': 'South', 'product': 'B', 'month': '2024-01', 'sales': 90, 'profit': 18},
        {'region': 'South', 'product': 'B', 'month': '2024-02', 'sales': 110, 'profit': 22},
    ]
    
    aggregator = DataAggregator()
    
    # Group by region and product, aggregate sales and profit
    result = aggregator.aggregate(
        sales_data, 
        group_by=['region', 'product'],
        aggregations={'sales': 'sum', 'profit': 'avg'}
    )
    print("Aggregated data:", result)
    
    # Create pivot table
    pivot = aggregator.pivot_table(sales_data, 'region', 'product', 'sales')
    print("Pivot table:", pivot)
    
    # Apply window function
    windowed = aggregator.window_function(
        sales_data, 
        partition_by=['region'], 
        order_by='month', 
        window_func='running_sum', 
        target_field='sales'
    )
    print("Window function result:", windowed[:2])
    ```

??? question "Q19: How do you build a multi-level cache system with dictionaries?"
    ```python
    import time
    import threading
    from typing import Any, Optional, Dict
    from collections import OrderedDict
    import weakref
    
    class MultiLevelCache:
        def __init__(self, l1_size=100, l2_size=1000, l1_ttl=300, l2_ttl=3600):
            self.l1_cache = OrderedDict()  # LRU cache
            self.l2_cache = {}  # Simple dict cache
            self.l1_size = l1_size
            self.l2_size = l2_size
            self.l1_ttl = l1_ttl
            self.l2_ttl = l2_ttl
            
            self.l1_timestamps = {}
            self.l2_timestamps = {}
            self.access_counts = {}
            self.lock = threading.RLock()
            
            # Stats
            self.stats = {
                'l1_hits': 0, 'l2_hits': 0, 'misses': 0,
                'l1_evictions': 0, 'l2_evictions': 0
            }
        
        def _is_expired(self, key: str, level: int) -> bool:
            """Check if cache entry is expired"""
            timestamps = self.l1_timestamps if level == 1 else self.l2_timestamps
            ttl = self.l1_ttl if level == 1 else self.l2_ttl
            
            if key not in timestamps:
                return True
            
            return time.time() - timestamps[key] > ttl
        
        def _promote_to_l1(self, key: str, value: Any):
            """Promote frequently accessed item to L1 cache"""
            with self.lock:
                # Remove from L2
                if key in self.l2_cache:
                    del self.l2_cache[key]
                    del self.l2_timestamps[key]
                
                # Add to L1
                self._set_l1(key, value)
        
        def _set_l1(self, key: str, value: Any):
            """Set value in L1 cache with LRU eviction"""
            with self.lock:
                if key in self.l1_cache:
                    self.l1_cache.move_to_end(key)
                else:
                    # Check size limit
                    while len(self.l1_cache) >= self.l1_size:
                        old_key, old_value = self.l1_cache.popitem(last=False)
                        del self.l1_timestamps[old_key]
                        self.stats['l1_evictions'] += 1
                        
                        # Demote to L2 if still valuable
                        if old_key in self.access_counts and self.access_counts[old_key] > 1:
                            self._set_l2(old_key, old_value)
                
                self.l1_cache[key] = value
                self.l1_timestamps[key] = time.time()
        
        def _set_l2(self, key: str, value: Any):
            """Set value in L2 cache with size limit"""
            with self.lock:
                # Check size limit
                while len(self.l2_cache) >= self.l2_size:
                    # Remove oldest entry
                    oldest_key = min(self.l2_timestamps.keys(), 
                                   key=lambda k: self.l2_timestamps[k])
                    del self.l2_cache[oldest_key]
                    del self.l2_timestamps[oldest_key]
                    self.stats['l2_evictions'] += 1
                
                self.l2_cache[key] = value
                self.l2_timestamps[key] = time.time()
        
        def get(self, key: str) -> Optional[Any]:
            """Get value from cache (L1 -> L2 -> miss)"""
            with self.lock:
                # Update access count
                self.access_counts[key] = self.access_counts.get(key, 0) + 1
                
                # Try L1 cache
                if key in self.l1_cache and not self._is_expired(key, 1):
                    self.l1_cache.move_to_end(key)  # Update LRU
                    self.stats['l1_hits'] += 1
                    return self.l1_cache[key]
                
                # Try L2 cache
                if key in self.l2_cache and not self._is_expired(key, 2):
                    value = self.l2_cache[key]
                    self.stats['l2_hits'] += 1
                    
                    # Promote to L1 if frequently accessed
                    if self.access_counts[key] > 3:
                        self._promote_to_l1(key, value)
                    
                    return value
                
                # Cache miss
                self.stats['misses'] += 1
                return None
        
        def set(self, key: str, value: Any, prefer_l1: bool = False):
            """Set value in cache"""
            with self.lock:
                # Remove from both caches if exists
                if key in self.l1_cache:
                    del self.l1_cache[key]
                    del self.l1_timestamps[key]
                if key in self.l2_cache:
                    del self.l2_cache[key]
                    del self.l2_timestamps[key]
                
                # Decide placement
                if prefer_l1 or self.access_counts.get(key, 0) > 2:
                    self._set_l1(key, value)
                else:
                    self._set_l2(key, value)
        
        def delete(self, key: str):
            """Delete key from all cache levels"""
            with self.lock:
                if key in self.l1_cache:
                    del self.l1_cache[key]
                    del self.l1_timestamps[key]
                if key in self.l2_cache:
                    del self.l2_cache[key]
                    del self.l2_timestamps[key]
                if key in self.access_counts:
                    del self.access_counts[key]
        
        def clear(self):
            """Clear all cache levels"""
            with self.lock:
                self.l1_cache.clear()
                self.l2_cache.clear()
                self.l1_timestamps.clear()
                self.l2_timestamps.clear()
                self.access_counts.clear()
        
        def get_stats(self) -> Dict[str, Any]:
            """Get cache statistics"""
            total_requests = sum(self.stats.values())
            hit_rate = (self.stats['l1_hits'] + self.stats['l2_hits']) / max(total_requests, 1)
            
            return {
                **self.stats,
                'l1_size': len(self.l1_cache),
                'l2_size': len(self.l2_cache),
                'hit_rate': round(hit_rate * 100, 2),
                'l1_hit_rate': round(self.stats['l1_hits'] / max(total_requests, 1) * 100, 2),
                'l2_hit_rate': round(self.stats['l2_hits'] / max(total_requests, 1) * 100, 2)
            }
    
    # Example usage
    cache = MultiLevelCache(l1_size=3, l2_size=5, l1_ttl=10, l2_ttl=30)
    
    # Simulate cache usage
    for i in range(10):
        cache.set(f"key_{i}", f"value_{i}")
    
    # Access some keys multiple times to trigger promotion
    for _ in range(5):
        cache.get("key_1")
        cache.get("key_2")
        cache.get("key_3")
    
    print("Cache stats:", cache.get_stats())
    print("L1 cache:", dict(cache.l1_cache))
    print("L2 cache:", cache.l2_cache)
    ```

??? question "Q20: How do you implement a schema validator using dictionaries?"
    ```python
    from typing import Any, Dict, List, Union, Optional, Callable
    import re
    from datetime import datetime
    
    class SchemaValidator:
        def __init__(self):
            self.type_validators = {
                'string': self._validate_string,
                'integer': self._validate_integer,
                'float': self._validate_float,
                'boolean': self._validate_boolean,
                'array': self._validate_array,
                'object': self._validate_object,
                'datetime': self._validate_datetime,
                'email': self._validate_email,
                'url': self._validate_url
            }
        
        def _validate_string(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, str):
                return False, f"Expected string, got {type(value).__name__}"
            
            if 'min_length' in constraints and len(value) < constraints['min_length']:
                return False, f"String too short (min: {constraints['min_length']})"
            
            if 'max_length' in constraints and len(value) > constraints['max_length']:
                return False, f"String too long (max: {constraints['max_length']})"
            
            if 'pattern' in constraints:
                if not re.match(constraints['pattern'], value):
                    return False, f"String doesn't match pattern: {constraints['pattern']}"
            
            if 'enum' in constraints and value not in constraints['enum']:
                return False, f"Value must be one of: {constraints['enum']}"
            
            return True, ""
        
        def _validate_integer(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, int) or isinstance(value, bool):
                return False, f"Expected integer, got {type(value).__name__}"
            
            if 'minimum' in constraints and value < constraints['minimum']:
                return False, f"Value too small (min: {constraints['minimum']})"
            
            if 'maximum' in constraints and value > constraints['maximum']:
                return False, f"Value too large (max: {constraints['maximum']})"
            
            return True, ""
        
        def _validate_float(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, (int, float)) or isinstance(value, bool):
                return False, f"Expected number, got {type(value).__name__}"
            
            if 'minimum' in constraints and value < constraints['minimum']:
                return False, f"Value too small (min: {constraints['minimum']})"
            
            if 'maximum' in constraints and value > constraints['maximum']:
                return False, f"Value too large (max: {constraints['maximum']})"
            
            return True, ""
        
        def _validate_boolean(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, bool):
                return False, f"Expected boolean, got {type(value).__name__}"
            return True, ""
        
        def _validate_array(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, list):
                return False, f"Expected array, got {type(value).__name__}"
            
            if 'min_items' in constraints and len(value) < constraints['min_items']:
                return False, f"Array too short (min: {constraints['min_items']})"
            
            if 'max_items' in constraints and len(value) > constraints['max_items']:
                return False, f"Array too long (max: {constraints['max_items']})"
            
            # Validate items
            if 'items' in constraints:
                for i, item in enumerate(value):
                    valid, error = self.validate_value(item, constraints['items'])
                    if not valid:
                        return False, f"Item {i}: {error}"
            
            return True, ""
        
        def _validate_object(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, dict):
                return False, f"Expected object, got {type(value).__name__}"
            
            # Check required properties
            if 'required' in constraints:
                for prop in constraints['required']:
                    if prop not in value:
                        return False, f"Missing required property: {prop}"
            
            # Validate properties
            if 'properties' in constraints:
                for prop, prop_schema in constraints['properties'].items():
                    if prop in value:
                        valid, error = self.validate_value(value[prop], prop_schema)
                        if not valid:
                            return False, f"Property '{prop}': {error}"
            
            # Check for additional properties
            if constraints.get('additional_properties', True) is False:
                allowed_props = set(constraints.get('properties', {}).keys())
                actual_props = set(value.keys())
                extra_props = actual_props - allowed_props
                if extra_props:
                    return False, f"Additional properties not allowed: {extra_props}"
            
            return True, ""
        
        def _validate_datetime(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if isinstance(value, str):
                try:
                    datetime.fromisoformat(value.replace('Z', '+00:00'))
                    return True, ""
                except ValueError:
                    return False, "Invalid datetime format"
            return False, f"Expected datetime string, got {type(value).__name__}"
        
        def _validate_email(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, str):
                return False, f"Expected string, got {type(value).__name__}"
            
            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}
            if not re.match(email_pattern, value):
                return False, "Invalid email format"
            
            return True, ""
        
        def _validate_url(self, value: Any, constraints: Dict) -> tuple[bool, str]:
            if not isinstance(value, str):
                return False, f"Expected string, got {type(value).__name__}"
            
            url_pattern = r'^https?://[^\s/$.?#].[^\s]*
            if not re.match(url_pattern, value):
                return False, "Invalid URL format"
            
            return True, ""
        
        def validate_value(self, value: Any, schema: Dict) -> tuple[bool, str]:
            """Validate a single value against schema"""
            
            # Handle null values
            if value is None:
                if schema.get('nullable', False):
                    return True, ""
                else:
                    return False, "Value cannot be null"
            
            # Get type and validator
            value_type = schema.get('type')
            if value_type not in self.type_validators:
                return False, f"Unknown type: {value_type}"
            
            validator = self.type_validators[value_type]
            return validator(value, schema)
        
        def validate(self, data: Dict[str, Any], schema: Dict[str, Any]) -> Dict[str, Any]:
            """Validate data against schema, return validation result"""
            
            result = {
                'valid': True,
                'errors': [],
                'warnings': []
            }
            
            # Validate root object
            valid, error = self._validate_object(data, schema)
            if not valid:
                result['valid'] = False
                result['errors'].append(error)
            
            return result
        
        def get_schema_template(self, sample_data: Dict[str, Any]) -> Dict[str, Any]:
            """Generate schema template from sample data"""
            
            def infer_type(value):
                if isinstance(value, bool):
                    return {'type': 'boolean'}
                elif isinstance(value, int):
                    return {'type': 'integer'}
                elif isinstance(value, float):
                    return {'type': 'float'}
                elif isinstance(value, str):
                    # Try to infer more specific types
                    if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}, value):
                        return {'type': 'email'}
                    elif re.match(r'^https?://[^\s/$.?#].[^\s]*, value):
                        return {'type': 'url'}
                    else:
                        return {'type': 'string', 'max_length': len(value) * 2}
                elif isinstance(value, list):
                    item_schema = infer_type(value[0]) if value else {'type': 'string'}
                    return {'type': 'array', 'items': item_schema}
                elif isinstance(value, dict):
                    return self.get_schema_template(value)
                else:
                    return {'type': 'string'}
            
            properties = {}
            required = []
            
            for key, value in sample_data.items():
                if value is not None:
                    properties[key] = infer_type(value)
                    required.append(key)
                else:
                    properties[key] = {'type': 'string', 'nullable': True}
            
            return {
                'type': 'object',
                'properties': properties,
                'required': required,
                'additional_properties': False
            }
    
    # Example usage
    validator = SchemaValidator()
    
    # Define schema
    user_schema = {
        'type': 'object',
        'properties': {
            'name': {
                'type': 'string',
                'min_length': 2,
                'max_length': 50
            },
            'email': {
                'type': 'email'
            },
            'age': {
                'type': 'integer',
                'minimum': 0,
                'maximum': 150
            },
            'preferences': {
                'type': 'object',
                'properties': {
                    'theme': {
                        'type': 'string',
                        'enum': ['light', 'dark']
                    },
                    'notifications': {
                        'type': 'boolean'
                    }
                },
                'required': ['theme']
            },
            'tags': {
                'type': 'array',
                'items': {'type': 'string'},
                'max_items': 10
            }
        },
        'required': ['name', 'email'],
        'additional_properties': False
    }
    
    # Test data
    valid_user = {
        'name': 'John Doe',
        'email': 'john@example.com',
        'age': 30,
        'preferences': {
            'theme': 'dark',
            'notifications': True
        },
        'tags': ['developer', 'python']
    }
    
    invalid_user = {
        'name': 'J',  # Too short
        'email': 'invalid-email',  # Invalid format
        'age': 200,  # Too high
        'preferences': {
            'theme': 'blue'  # Not in enum
        }
        # Missing required email
    }
    
    # Validate
    result1 = validator.validate(valid_user, user_schema)
    result2 = validator.validate(invalid_user, user_schema)
    
    print("Valid user:", result1)
    print("Invalid user:", result2)
    
    # Generate schema from sample
    sample_data = {'name': 'John', 'age': 30, 'email': 'john@test.com'}
    generated_schema = validator.get_schema_template(sample_data)
    print("Generated schema:", generated_schema)
    ```

---

## 🎯 Bonus Advanced Questions

??? question "Q21: How do you implement a thread-safe dictionary with custom locking?"
    ```python
    import threading
    from typing import Any, Dict, Optional, Iterator
    from contextlib import contextmanager
    
    class ThreadSafeDict:
        def __init__(self, initial_data: Dict = None):
            self._data = initial_data or {}
            self._locks = {}  # Per-key locks for fine-grained locking
            self._global_lock = threading.RLock()
            self._readers = {}  # Reader count per key
            self._readers_lock = threading.Lock()
        
        def _get_key_lock(self, key: str) -> threading.RLock:
            """Get or create lock for specific key"""
            with self._global_lock:
                if key not in self._locks:
                    self._locks[key] = threading.RLock()
                return self._locks[key]
        
        @contextmanager
        def _read_lock(self, key: str):
            """Context manager for read operations"""
            with self._readers_lock:
                self._readers[key] = self._readers.get(key, 0) + 1
            
            try:
                yield
            finally:
                with self._readers_lock:
                    self._readers[key] -= 1
                    if self._readers[key] == 0:
                        del self._readers[key]
        
        @contextmanager
        def _write_lock(self, key: str):
            """Context manager for write operations"""
            key_lock = self._get_key_lock(key)
            with key_lock:
                # Wait for readers to finish
                while key in self._readers and self._readers[key] > 0:
                    threading.Event().wait(0.001)  # Small delay
                yield
        
        def get(self, key: str, default: Any = None) -> Any:
            """Thread-safe get operation"""
            with self._read_lock(key):
                return self._data.get(key, default)
        
        def set(self, key: str, value: Any) -> None:
            """Thread-safe set operation"""
            with self._write_lock(key):
                self._data[key] = value
        
        def delete(self, key: str) -> bool:
            """Thread-safe delete operation"""
            with self._write_lock(key):
                if key in self._data:
                    del self._data[key]
                    return True
                return False
        
        def update(self, other: Dict[str, Any]) -> None:
            """Thread-safe bulk update"""
            # Sort keys to prevent deadlock
            keys = sorted(other.keys())
            locks = [self._get_key_lock(key) for key in keys]
            
            # Acquire all locks in order
            for lock in locks:
                lock.acquire()
            
            try:
                for key, value in other.items():
                    self._data[key] = value
            finally:
                # Release all locks in reverse order
                for lock in reversed(locks):
                    lock.release()
        
        def atomic_increment(self, key: str, delta: int = 1) -> int:
            """Atomically increment a numeric value"""
            with self._write_lock(key):
                current = self._data.get(key, 0)
                if not isinstance(current, (int, float)):
                    raise ValueError(f"Cannot increment non-numeric value: {current}")
                new_value = current + delta
                self._data[key] = new_value
                return new_value
        
        def compare_and_swap(self, key: str, expected: Any, new_value: Any) -> bool:
            """Atomic compare and swap operation"""
            with self._write_lock(key):
                current = self._data.get(key)
                if current == expected:
                    self._data[key] = new_value
                    return True
                return False
        
        def keys(self) -> Iterator[str]:
            """Get all keys (snapshot)"""
            with self._global_lock:
                return iter(list(self._data.keys()))
        
        def items(self) -> Iterator[tuple]:
            """Get all items (snapshot)"""
            with self._global_lock:
                return iter(list(self._data.items()))
        
        def __len__(self) -> int:
            with self._global_lock:
                return len(self._data)
        
        def __contains__(self, key: str) -> bool:
            with self._read_lock(key):
                return key in self._data
    
    # Example usage
    thread_dict = ThreadSafeDict()
    
    def worker(thread_id: int):
        for i in range(100):
            key = f"counter_{i % 10}"
            thread_dict.atomic_increment(key, 1)
            thread_dict.set(f"thread_{thread_id}_item_{i}", f"value_{i}")
    
    # Test with multiple threads
    import threading
    threads = []
    for i in range(5):
        t = threading.Thread(target=worker, args=(i,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    print("Final counters:", {k: v for k, v in thread_dict.items() if k.startswith('counter_')})
    ```

??? question "Q22: How do you implement a dictionary-based state machine?"
    ```python
    from typing import Dict, Any, Callable, Optional, List
    from enum import Enum
    import logging
    
    class StateTransitionError(Exception):
        pass
    
    class StateMachine:
        def __init__(self, initial_state: str):
            self.current_state = initial_state
            self.states: Dict[str, Dict[str, Any]] = {}
            self.transitions: Dict[tuple, Dict[str, Any]] = {}
            self.global_handlers: Dict[str, Callable] = {}
            self.history: List[Dict[str, Any]] = []
            self.context: Dict[str, Any] = {}
            
        def add_state(self, name: str, 
                     on_enter: Optional[Callable] = None,
                     on_exit: Optional[Callable] = None,
                     on_update: Optional[Callable] = None,
                     metadata: Optional[Dict] = None):
            """Add a state to the state machine"""
            self.states[name] = {
                'on_enter': on_enter,
                'on_exit': on_exit,
                'on_update': on_update,
                'metadata': metadata or {}
            }
        
        def add_transition(self, from_state: str, to_state: str, 
                          event: str, 
                          condition: Optional[Callable] = None,
                          action: Optional[Callable] = None,
                          priority: int = 0):
            """Add a transition between states"""
            key = (from_state, event)
            if key not in self.transitions:
                self.transitions[key] = []
            
            self.transitions[key].append({
                'to_state': to_state,
                'condition': condition,
                'action': action,
                'priority': priority
            })
            
            # Sort by priority (higher priority first)
            self.transitions[key].sort(key=lambda x: x['priority'], reverse=True)
        
        def add_wildcard_transition(self, event: str, to_state: str,
                                   condition: Optional[Callable] = None,
                                   action: Optional[Callable] = None):
            """Add transition that works from any state"""
            for state in self.states:
                self.add_transition(state, to_state, event, condition, action)
        
        def trigger_event(self, event: str, **kwargs) -> bool:
            """Trigger an event and attempt state transition"""
            
            # Update context with event data
            self.context.update(kwargs)
            
            # Look for matching transitions
            key = (self.current_state, event)
            if key not in self.transitions:
                logging.warning(f"No transition for event '{event}' from state '{self.current_state}'")
                return False
            
            # Try transitions in priority order
            for transition in self.transitions[key]:
                # Check condition
                if transition['condition']:
                    try:
                        if not transition['condition'](self.context):
                            continue
                    except Exception as e:
                        logging.error(f"Condition check failed: {e}")
                        continue
                
                # Perform transition
                old_state = self.current_state
                new_state = transition['to_state']
                
                try:
                    # Exit current state
                    if self.states[old_state]['on_exit']:
                        self.states[old_state]['on_exit'](self.context)
                    
                    # Execute transition action
                    if transition['action']:
                        transition['action'](self.context)
                    
                    # Change state
                    self.current_state = new_state
                    
                    # Enter new state
                    if self.states[new_state]['on_enter']:
                        self.states[new_state]['on_enter'](self.context)
                    
                    # Record history
                    self.history.append({
                        'from_state': old_state,
                        'to_state': new_state,
                        'event': event,
                        'context': dict(self.context),
                        'timestamp': __import__('time').time()
                    })
                    
                    logging.info(f"Transitioned from '{old_state}' to '{new_state}' on event '{event}'")
                    return True
                
                except Exception as e:
                    logging.error(f"Transition failed: {e}")
                    # Rollback if needed
                    self.current_state = old_state
                    raise StateTransitionError(f"Failed to transition: {e}")
            
            return False
        
        def update(self):
            """Update current state (call on_update handler)"""
            if self.current_state in self.states:
                handler = self.states[self.current_state]['on_update']
                if handler:
                    handler(self.context)
        
        def can_transition(self, event: str, **kwargs) -> bool:
            """Check if transition is possible without executing it"""
            temp_context = {**self.context, **kwargs}
            key = (self.current_state, event)
            
            if key not in self.transitions:
                return False
            
            for transition in self.transitions[key]:
                if transition['condition']:
                    try:
                        if transition['condition'](temp_context):
                            return True
                    except:
                        continue
                else:
                    return True
            
            return False
        
        def get_available_events(self) -> List[str]:
            """Get list of events that can be triggered from current state"""
            events = []
            for (state, event), transitions in self.transitions.items():
                if state == self.current_state:
                    for transition in transitions:
                        if not transition['condition'] or transition['condition'](self.context):
                            events.append(event)
                            break
            return list(set(events))
        
        def rollback(self, steps: int = 1) -> bool:
            """Rollback to previous state(s)"""
            if len(self.history) < steps:
                return False
            
            target_entry = self.history[-(steps + 1)] if len(self.history) > steps else None
            if not target_entry:
                return False
            
            old_state = self.current_state
            target_state = target_entry['from_state']
            
            try:
                # Exit current state
                if self.states[old_state]['on_exit']:
                    self.states[old_state]['on_exit'](self.context)
                
                # Change state
                self.current_state = target_state
                
                # Enter target state
                if self.states[target_state]['on_enter']:
                    self.states[target_state]['on_enter'](self.context)
                
                # Remove rolled back history
                self.history = self.history[:-steps]
                
                return True
            except Exception as e:
                logging.error(f"Rollback failed: {e}")
                self.current_state = old_state
                return False
        
        def to_dict(self) -> Dict[str, Any]:
            """Export state machine configuration"""
            return {
                'current_state': self.current_state,
                'states': {k: {**v, 'on_enter': v['on_enter'].__name__ if v['on_enter'] else None,
                             'on_exit': v['on_exit'].__name__ if v['on_exit'] else None,
                             'on_update': v['on_update'].__name__ if v['on_update'] else None}
                          for k, v in self.states.items()},
                'transitions': {f"{k[0]}-{k[1]}": v for k, v in self.transitions.items()},
                'context': self.context,
                'history': self.history[-10:]  # Last 10 transitions
            }
    
    # Example: Traffic Light State Machine
    class TrafficLight:
        def __init__(self):
            self.sm = StateMachine('red')
            self.timer = 0
            self.setup_states()
            self.setup_transitions()
        
        def setup_states(self):
            self.sm.add_state('red', 
                            on_enter=lambda ctx: self.reset_timer(),
                            on_update=lambda ctx: self.update_timer(),
                            metadata={'duration': 30, 'color': 'red'})
            
            self.sm.add_state('yellow', 
                            on_enter=lambda ctx: self.reset_timer(),
                            on_update=lambda ctx: self.update_timer(),
                            metadata={'duration': 5, 'color': 'yellow'})
            
            self.sm.add_state('green', 
                            on_enter=lambda ctx: self.reset_timer(),
                            on_update=lambda ctx: self.update_timer(),
                            metadata={'duration': 25, 'color': 'green'})
        
        def setup_transitions(self):
            # Normal cycle
            self.sm.add_transition('red', 'green', 'timer_expired',
                                 condition=lambda ctx: ctx.get('timer', 0) >= 30)
            
            self.sm.add_transition('green', 'yellow', 'timer_expired',
                                 condition=lambda ctx: ctx.get('timer', 0) >= 25)
            
            self.sm.add_transition('yellow', 'red', 'timer_expired',
                                 condition=lambda ctx: ctx.get('timer', 0) >= 5)
            
            # Emergency override
            self.sm.add_wildcard_transition('emergency', 'red',
                                          action=lambda ctx: ctx.update({'emergency_mode': True}))
            
            # Manual control
            self.sm.add_transition('red', 'green', 'manual_override',
                                 condition=lambda ctx: ctx.get('manual_mode', False))
        
        def reset_timer(self):
            self.timer = 0
            self.sm.context['timer'] = 0
        
        def update_timer(self):
            self.timer += 1
            self.sm.context['timer'] = self.timer
            
            # Auto-trigger timer events
            if self.sm.can_transition('timer_expired'):
                self.sm.trigger_event('timer_expired')
        
        def emergency_stop(self):
            self.sm.trigger_event('emergency')
        
        def manual_control(self, enabled: bool):
            self.sm.context['manual_mode'] = enabled
            if enabled and self.sm.current_state == 'red':
                self.sm.trigger_event('manual_override')
        
        def get_status(self):
            current_state = self.sm.states[self.sm.current_state]
            return {
                'light': current_state['metadata']['color'],
                'timer': self.timer,
                'state': self.sm.current_state,
                'available_events': self.sm.get_available_events(),
                'context': dict(self.sm.context)
            }
    
    # Example usage
    traffic_light = TrafficLight()
    
    # Simulate traffic light operation
    for i in range(70):  # 70 seconds
        traffic_light.sm.update()
        if i % 10 == 0:  # Print status every 10 seconds
            print(f"Time {i}: {traffic_light.get_status()}")
        
        # Test emergency at 35 seconds
        if i == 35:
            traffic_light.emergency_stop()
            print(f"Emergency triggered: {traffic_light.get_status()}")
    
    # Print final state machine configuration
    print("\nFinal state machine:", traffic_light.sm.to_dict())
    ```

??? question "Q23: How do you implement a distributed dictionary with conflict resolution?"
    ```python
    import time
    import json
    import hashlib
    from typing import Dict, Any, Optional, List, Tuple
    from dataclasses import dataclass, asdict
    from collections import defaultdict
    
    @dataclass
    class VectorClock:
        clocks: Dict[str, int]
        
        def __post_init__(self):
            if not hasattr(self, 'clocks'):
                self.clocks = {}
        
        def increment(self, node_id: str):
            self.clocks[node_id] = self.clocks.get(node_id, 0) + 1
        
        def update(self, other: 'VectorClock'):
            for node_id, clock in other.clocks.items():
                self.clocks[node_id] = max(self.clocks.get(node_id, 0), clock)
        
        def happens_before(self, other: 'VectorClock') -> bool:
            """Check if this event happens before another"""
            if not self.clocks or not other.clocks:
                return False
            
            at_least_one_less = False
            for node_id in set(self.clocks.keys()) | set(other.clocks.keys()):
                self_clock = self.clocks.get(node_id, 0)
                other_clock = other.clocks.get(node_id, 0)
                
                if self_clock > other_clock:
                    return False
                elif self_clock < other_clock:
                    at_least_one_less = True
            
            return at_least_one_less
        
        def concurrent_with(self, other: 'VectorClock') -> bool:
            """Check if events are concurrent (conflicting)"""
            return not self.happens_before(other) and not other.happens_before(self)
    
    @dataclass
    class VersionedValue:
        value: Any
        vector_clock: VectorClock
        timestamp: float
        node_id: str
        version_hash: str = ""
        
        def __post_init__(self):
            if not self.version_hash:
                content = json.dumps([self.value, asdict(self.vector_clock), self.timestamp], 
                                   sort_keys=True)
                self.version_hash = hashlib.md5(content.encode()).hexdigest()
    
    class ConflictResolver:
        """Different conflict resolution strategies"""
        
        @staticmethod
        def last_write_wins(versions: List[VersionedValue]) -> VersionedValue:
            """Resolve by latest timestamp"""
            return max(versions, key=lambda v: v.timestamp)
        
        @staticmethod
        def vector_clock_resolve(versions: List[VersionedValue]) -> List[VersionedValue]:
            """Resolve using vector clocks, return non-conflicting versions"""
            if len(versions) <= 1:
                return versions
            
            # Find versions that don't happen before any other
            result = []
            for i, v1 in enumerate(versions):
                is_superseded = False
                for j, v2 in enumerate(versions):
                    if i != j and v1.vector_clock.happens_before(v2.vector_clock):
                        is_superseded = True
                        break
                
                if not is_superseded:
                    result.append(v1)
            
            return result if result else [versions[-1]]
        
        @staticmethod
        def custom_merge(versions: List[VersionedValue], merge_func) -> VersionedValue:
            """Custom merge function"""
            if len(versions) == 1:
                return versions[0]
            
            # Sort by timestamp
            sorted_versions = sorted(versions, key=lambda v: v.timestamp)
            
            # Merge values
            merged_value = merge_func([v.value for v in sorted_versions])
            
            # Create new vector clock
            merged_clock = VectorClock({})
            for version in versions:
                merged_clock.update(version.vector_clock)
            
            return VersionedValue(
                value=merged_value,
                vector_clock=merged_clock,
                timestamp=time.time(),
                node_id="merged"
            )
    
    class DistributedDict:
        def __init__(self, node_id: str, conflict_strategy: str = 'vector_clock'):
            self.node_id = node_id
            self.data: Dict[str, List[VersionedValue]] = defaultdict(list)
            self.vector_clock = VectorClock({})
            self.conflict_strategy = conflict_strategy
            
            self.conflict_resolvers = {
                'last_write_wins': ConflictResolver.last_write_wins,
                'vector_clock': ConflictResolver.vector_clock_resolve,
            }
        
        def set(self, key: str, value: Any) -> VersionedValue:
            """Set a value with versioning"""
            # Increment our clock
            self.vector_clock.increment(self.node_id)
            
            # Create versioned value
            versioned = VersionedValue(
                value=value,
                vector_clock=VectorClock(dict(self.vector_clock.clocks)),
                timestamp=time.time(),
                node_id=self.node_id
            )
            
            # Add to versions (conflict resolution happens on get)
            self.data[key].append(versioned)
            
            # Cleanup old versions (keep last 10)
            if len(self.data[key]) > 10:
                self.data[key] = self.data[key][-10:]
            
            return versioned
        
        def get(self, key: str, resolve_conflicts: bool = True) -> Any:
            """Get value, resolving conflicts if needed"""
            if key not in self.data:
                return None
            
            versions = self.data[key]
            if not versions:
                return None
            
            if not resolve_conflicts:
                return [v.value for v in versions]
            
            # Resolve conflicts
            if self.conflict_strategy == 'vector_clock':
                resolved_versions = self.conflict_resolvers['vector_clock'](versions)
                if len(resolved_versions) == 1:
                    return resolved_versions[0].value
                else:
                    # Still have conflicts, use last write wins
                    return self.conflict_resolvers['last_write_wins'](resolved_versions).value
            else:
                resolver = self.conflict_resolvers.get(self.conflict_strategy)
                if resolver:
                    return resolver(versions).value
            
            return versions[-1].value  # Fallback
        
        def get_versions(self, key: str) -> List[VersionedValue]:
            """Get all versions of a key"""
            return self.data.get(key, [])
        
        def merge_from_peer(self, peer_data: Dict[str, List[Dict]], peer_node_id: str):
            """Merge data from another node"""
            
            for key, peer_versions_data in peer_data.items():
                for version_data in peer_versions_data:
                    # Reconstruct VersionedValue
                    peer_version = VersionedValue(
                        value=version_data['value'],
                        vector_clock=VectorClock(version_data['vector_clock']['clocks']),
                        timestamp=version_data['timestamp'],
                        node_id=version_data['node_id'],
                        version_hash=version_data['version_hash']
                    )
                    
                    # Check if we already have this version
                    existing_hashes = {v.version_hash for v in self.data[key]}
                    if peer_version.version_hash not in existing_hashes:
                        self.data[key].append(peer_version)
                        # Update our vector clock
                        self.vector_clock.update(peer_version.vector_clock)
        
        def detect_conflicts(self, key: str) -> List[Tuple[VersionedValue, VersionedValue]]:
            """Detect conflicting versions for a key"""
            versions = self.data.get(key, [])
            conflicts = []
            
            for i, v1 in enumerate(versions):
                for j, v2 in enumerate(versions[i+1:], i+1):
                    if v1.vector_clock.concurrent_with(v2.vector_clock):
                        conflicts.append((v1, v2))
            
            return conflicts
        
        def resolve_conflict_manually(self, key: str, chosen_version_hash: str):
            """Manually resolve conflict by choosing a version"""
            if key not in self.data:
                return False
            
            chosen_version = None
            for version in self.data[key]:
                if version.version_hash == chosen_version_hash:
                    chosen_version = version
                    break
            
            if chosen_version:
                # Keep only the chosen version
                self.data[key] = [chosen_version]
                return True
            
            return False
        
        def set_custom_resolver(self, key: str, merge_func):
            """Set custom conflict resolution for specific key"""
            def custom_resolver(versions):
                return ConflictResolver.custom_merge(versions, merge_func)
            
            # Store resolver for this key
            if not hasattr(self, '_custom_resolvers'):
                self._custom_resolvers = {}
            self._custom_resolvers[key] = custom_resolver
        
        def export_data(self) -> Dict[str, List[Dict]]:
            """Export data for synchronization"""
            result = {}
            for key, versions in self.data.items():
                result[key] = []
                for version in versions:
                    result[key].append({
                        'value': version.value,
                        'vector_clock': asdict(version.vector_clock),
                        'timestamp': version.timestamp,
                        'node_id': version.node_id,
                        'version_hash': version.version_hash
                    })
            return result
        
        def get_stats(self) -> Dict[str, Any]:
            """Get statistics about the distributed dictionary"""
            total_versions = sum(len(versions) for versions in self.data.values())
            conflict_count = sum(len(self.detect_conflicts(key)) for key in self.data.keys())
            
            return {
                'node_id': self.node_id,
                'total_keys': len(self.data),
                'total_versions': total_versions,
                'conflicts': conflict_count,
                'vector_clock': dict(self.vector_clock.clocks)
            }
    
    # Example usage and simulation
    def simulate_distributed_system():
        # Create three nodes
        node1 = DistributedDict("node1")
        node2 = DistributedDict("node2") 
        node3 = DistributedDict("node3")
        
        # Simulate concurrent updates
        print("=== Initial Updates ===")
        node1.set("counter", 1)
        node2.set("counter", 2)  # Conflict!
        node3.set("name", "Alice")
        
        print(f"Node1 counter: {node1.get('counter')}")
        print(f"Node2 counter: {node2.get('counter')}")
        
        # Simulate network synchronization
        print("\n=== After Synchronization ===")
        node1.merge_from_peer(node2.export_data(), "node2")
        node1.merge_from_peer(node3.export_data(), "node3")
        
        node2.merge_from_peer(node1.export_data(), "node1")
        node2.merge_from_peer(node3.export_data(), "node3")
        
        print(f"Node1 counter after sync: {node1.get('counter')}")
        print(f"Node2 counter after sync: {node2.get('counter')}")
        print(f"Conflicts in node1: {len(node1.detect_conflicts('counter'))}")
        
        # Show all versions
        print(f"All versions of 'counter' in node1:")
        for v in node1.get_versions('counter'):
            print(f"  Value: {v.value}, Node: {v.node_id}, Time: {v.timestamp:.2f}")
        
        # Stats
        print(f"\nNode1 stats: {node1.get_stats()}")
        print(f"Node2 stats: {node2.get_stats()}")
    
    # Run simulation
    simulate_distributed_system()
    ```

---

## 📝 Summary

This guide covers **23 unique dictionary question patterns** that eliminate redundancy from typical interview question sets. Each pattern represents a distinct algorithmic approach or real-world application:

### Core Patterns Covered:
1. **Basic Operations**: Sorting, merging, filtering, key existence
2. **Transformations**: Inversion, flattening, grouping, value transformation  
3. **Advanced Data Structures**: LRU cache, bidirectional dict, thread-safe dict
4. **Algorithms**: Memoization, graph algorithms, state machines
5. **Real-world Applications**: Text analysis, configuration management, data aggregation
6. **Distributed Systems**: Conflict resolution, vector clocks, synchronization

### Key Takeaways:
- Focus on **algorithmic thinking** rather than memorizing syntax
- Understand **time/space complexity** trade-offs
- Practice **real-world applications** beyond basic CRUD operations
- Master **advanced patterns** like caching, state management, and distributed systems
- Learn to **optimize for specific use cases** (thread safety, memory usage, performance)

Each question demonstrates practical programming skills that go beyond simple dictionary manipulation, preparing you for senior-level technical interviews.